{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba03e6cf-964c-418c-9be8-e4ce8e99173b",
   "metadata": {},
   "source": [
    "# 0. Run RNA-seq Alignment Pipeline\n",
    "\n",
    "This notebook executes a complete RNA-seq alignment pipeline by:\n",
    "1. Fetching sample metadata using nf-core/fetchngs\n",
    "2. Downloading and optionally subsampling FASTQ files\n",
    "3. Running the nf-core/rnaseq pipeline for alignment and quantification\n",
    "\n",
    "### Required User Input\n",
    "\n",
    "1. Define the following in the configuration cell:\n",
    "   - `EXPERIMENT_ID`: Unique identifier for the experiment\n",
    "   - `EXTRA_EXPERIMENT_IDS`: Extra IDs to process with the primary experiment_id\n",
    "   - `STAR_REFERENCE_DIRECTORY`: Path to reference genome files\n",
    "   - `AWS`: Boolean flag for AWS execution\n",
    "\n",
    "2. Ensure reference files are available:\n",
    "   - STAR index\n",
    "   - RSEM index\n",
    "   - Salmon index\n",
    "   - Reference FASTA\n",
    "   - GTF annotation\n",
    "   \n",
    "3. Copy and run nextflow commands in terminal\n",
    "\n",
    "#### Expected Input Files\n",
    "1. Configuration files in `configs/` directory:\n",
    "   - `fetchngs.config`\n",
    "   - `rnaseq.config`\n",
    "2. STAR index described above\n",
    "\n",
    "#### Output Files\n",
    "1. `fetchngs_output/`\n",
    "   - Sample metadata\n",
    "   - Downloaded FASTQ files\n",
    "2. `rnaseq_output/`\n",
    "   - Aligned BAM files\n",
    "   - Gene/transcript quantification\n",
    "   - MultiQC report\n",
    "   - Pipeline execution logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f25f446e-4af1-4e29-ab69-d80100afa075",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shlex\n",
    "import shutil\n",
    "import os \n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "import s3fs\n",
    "\n",
    "from src.utils import check_gzipped_fastq_integrity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3334f184",
   "metadata": {},
   "source": [
    "### 0.1 Configure Notebook\n",
    "\n",
    "#### Required Variable Definitions:\n",
    "\n",
    "Processing Parameters\n",
    "- *SAMPLING_DEPTH*: Target read depth for subsampling (default: 50M reads)\n",
    "- *SAMPLING_CUTOFF*: Threshold above which samples will be subsampled (default: 75M reads)\n",
    "- *AWS*: Boolean flag to determine if running on AWS infrastructure\n",
    "\n",
    "File Paths\n",
    "- *BASE_DIR*: Root directory path for the project (default: current working directory)\n",
    "- *CONFIG_DIR*: Directory containing Nextflow configuration files\n",
    "- *EXPERIMENT_ID*: Unique identifier for the experiment\n",
    "- *EXTRA_EXPERIMENT_IDS*: List of additional experiment IDs to process\n",
    "- *OUTPUT_DIR*: Output directory for pipeline results (default: BASE_DIR/expression_atlas/runs/EXPERIMENT_ID)\n",
    "- *STAR_REFERENCE_DIRECTORY*: Path to directory containing reference genome files\n",
    "- *STAR_S3_DIRECTORY*: S3 folder with star directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4dfd20ea-b986-487a-ac7e-ee7b589efe46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CONFIG_DIR and STAR_REFERENCE_DIRECTORY need to be set. Nexflow configs in configs directory. \n",
    "\n",
    "BASE_DIR = Path.cwd()\n",
    "EXPERIMENT_ID = BASE_DIR.parts[-2]\n",
    "EXTRA_EXPERIMENT_IDS = []\n",
    "\n",
    "CONFIG_DIR = BASE_DIR / 'configs'\n",
    "OUTPUT_DIR = BASE_DIR.parent\n",
    "\n",
    "STAR_REFERENCE_DIRECTORY = Path('/data/expression_atlas/genome/GRCh38.p14')\n",
    "STAR_S3_DIRECTORY = 's3://velia-data-dev/VDC_004_annotation/genomes/GRCh38.p14'\n",
    "AWS = False\n",
    "\n",
    "SAMPLING_DEPTH = 50000000\n",
    "SAMPLING_CUTOFF = 75000000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0504a75a",
   "metadata": {},
   "source": [
    "#### 0.2 Download reference if does not exist locally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e5d364-36da-4370-b22d-6b0db30ce4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if star index downloaded, and download if not. \n",
    "\n",
    "s3 = s3fs.S3FileSystem()\n",
    "\n",
    "STAR_REFERENCE_DIRECTORY.mkdir(exist_ok=True, parents=True)\n",
    "if not (\n",
    "    (STAR_REFERENCE_DIRECTORY / 'star').exists()\n",
    "    and (STAR_REFERENCE_DIRECTORY / 'salmon').exists()\n",
    "):\n",
    "    s3.get(STAR_S3_DIRECTORY, STAR_REFERENCE_DIRECTORY, recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc851d4",
   "metadata": {},
   "source": [
    "#### 0.3 Create fetchngs project file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86c993f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(OUTPUT_DIR / 'projects.txt', 'w') as f:\n",
    "    f.write(f'{EXPERIMENT_ID}\\n')\n",
    "    for ID in EXTRA_EXPERIMENT_IDS:\n",
    "        f.write(f'{ID}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7d32ee",
   "metadata": {},
   "source": [
    "#### 0.4 Run nf-core/fetchngs to retrieve experiment metadata required for running nf-core/rnaseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729d5bc2-8195-455b-a4dd-07e31bd8c654",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nxf_cmd_metadata = f\"\"\"\n",
    "nextflow run {BASE_DIR}/fetchngs \\\n",
    "--input {OUTPUT_DIR}/projects.txt \\\n",
    "--outdir {OUTPUT_DIR}/fetchngs_output \\\n",
    "--nf_core_pipeline rnaseq \\\n",
    "--skip_fastq_download \\\n",
    "-resume \\\n",
    "-profile docker \\\n",
    "-c {CONFIG_DIR}/fetchngs.config\n",
    "\"\"\"\n",
    "print(nxf_cmd_metadata.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1a2fe2-1964-4f6e-b05f-52a369ae1309",
   "metadata": {},
   "source": [
    "#### 0.5 Read samplesheet to determine if subsampling/filtering necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede09840-b2c6-454c-bbd5-9164fb2fccf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read samplesheet and determine if subsampling necessary. Filter unwanted samples/conditions out of samplesheet. \n",
    "\n",
    "samplesheet = pd.read_csv(\n",
    "    OUTPUT_DIR / 'fetchngs_output' / 'metadata' / f'{EXPERIMENT_ID}.runinfo_ftp.tsv', \n",
    "    sep='\\t',\n",
    ")\n",
    "subsample_on = (samplesheet['read_count'] > SAMPLING_CUTOFF).any()\n",
    "\n",
    "samples_to_remove = []\n",
    "samplesheet = samplesheet.loc[\n",
    "    ~samplesheet['experiment_accession'].isin(samples_to_remove)\n",
    "]\n",
    "\n",
    "samplesheet.to_csv(\n",
    "    OUTPUT_DIR / 'fetchngs_output' / 'metadata' / f'{EXPERIMENT_ID}.runinfo_ftp_edit.tsv',\n",
    "    sep='\\t',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef9d05e-65de-49c1-939f-61ed6dec4955",
   "metadata": {},
   "source": [
    "#### 0.6 Run custom download from sra bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026fcc52-0939-4448-8187-d942dda5fe48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify the path to downloaded metatdata below, for samplesheet.\n",
    "\n",
    "nxf_cmd_fastq = f\"\"\"\n",
    "nextflow run {BASE_DIR}/nf_download \\\n",
    "--samplesheet {OUTPUT_DIR}/fetchngs_output/metadata/{EXPERIMENT_ID}.runinfo_ftp_edit.tsv \\\n",
    "--output_directory {OUTPUT_DIR}/fetchngs_output/fastq \\\n",
    "--subsample {'true' if subsample_on else 'false'} \\\n",
    "--sampling_depth {SAMPLING_DEPTH} \\\n",
    "--sampling_cutoff {SAMPLING_CUTOFF} \\\n",
    "-w {OUTPUT_DIR}/work \\\n",
    "-profile {'docker' if not AWS else 'aws'}\n",
    "\"\"\"\n",
    "print(nxf_cmd_fastq.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2aa8d7-f957-4e45-9d7c-a2f74f6dee51",
   "metadata": {},
   "source": [
    "#### 0.7 Rearrange samplesheet fetch from fetchngs to make it compatible with nf-core rnaseq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c0910f-3603-40b5-bd4e-c7834dea5c97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samplesheet = pd.read_csv(\n",
    "    OUTPUT_DIR / 'fetchngs_output' / 'samplesheet' / 'samplesheet.csv'\n",
    ")\n",
    "\n",
    "# Populate correct paths in \n",
    "samplesheet.loc[:, 'fastq_1'] = samplesheet.apply(\n",
    "    lambda x:\n",
    "        OUTPUT_DIR / 'fetchngs_output' / 'fastq' / (\n",
    "            f'{x[\"experiment_accession\"]}_{x[\"run_accession\"]}.fastq.gz' if x[\"library_layout\"] == \"SINGLE\" else \n",
    "            f'{x[\"experiment_accession\"]}_{x[\"run_accession\"]}_1.fastq.gz'\n",
    "        )\n",
    "    axis=1,\n",
    ")\n",
    "samplesheet.loc[:, 'fastq_2'] = samplesheet.apply(\n",
    "    lambda x:\n",
    "        (OUTPUT_DIR / 'fetchngs_output' / 'fastq' / f'{x[\"experiment_accession\"]}_{x[\"run_accession\"]}_2.fastq.gz')\n",
    "        if x[\"library_layout\"] == \"SINGLE\" else None\n",
    "    axis=1,\n",
    ")\n",
    "# Filter samplesheet for samples that exist. \n",
    "samplesheet = samplesheet.loc[\n",
    "    samplesheet.apply(\n",
    "        lambda x: Path(x[\"fastq_1\"]).exists() if x[\"library_layout\"] == \"SINGLE\" else (\n",
    "            Path(x[\"fastq_1\"]).exists() and Path(x[\"fastq_2\"]).exists()\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "]\n",
    "\n",
    "# Check that fastqs that do exist are unzippable. \n",
    "samplesheet = samplesheet['fastq_1'].map(\n",
    "    lambda x: check_gzipped_fastq_integrity(x)\n",
    ")\n",
    "samplesheet = samplesheet['fastq_2'].map(\n",
    "    lambda x: check_gzipped_fastq_integrity(x)\n",
    ")\n",
    "\n",
    "samplesheet.to_csv(\n",
    "    OUTPUT_DIR, 'fetchngs_output' / 'samplesheet', 'samplesheet_edit.csv',\n",
    "    index=False, \n",
    "    quoting=csv.QUOTE_NONNUMERIC,\n",
    ")\n",
    "samplesheet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a48145-b238-4ca7-8d47-d7e324be83f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 0.8 Run nf-core/rnaseq pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32282f9d-94ae-4691-a39b-447abc05c6b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nxf_cmd_align = f\"\"\"\n",
    "nextflow run {BASE_DIR}/rnaseq \\\n",
    "--input {OUTPUT_DIR}/fetchngs_output/samplesheet/samplesheet_edit.csv \\\n",
    "--fasta {STAR_REFERENCE_DIRECTORY}/rsem/GRCh38.p14.genome.fa \\\n",
    "--gtf {STAR_REFERENCE_DIRECTORY}/veliadb_v0c.gtf \\\n",
    "--star_index {STAR_REFERENCE_DIRECTORY}/star \\\n",
    "--transcript_fasta {STAR_REFERENCE_DIRECTORY}/rsem/genome.transcripts.fa \\\n",
    "--rsem_index {STAR_REFERENCE_DIRECTORY}/rsem \\\n",
    "--salmon_index {STAR_REFERENCE_DIRECTORY}/salmon \\\n",
    "--outdir {OUTPUT_DIR}/rnaseq_output \\\n",
    "-w {OUTPUT_DIR}/work \\\n",
    "-profile docker \\\n",
    "-c {CONFIG_DIR}/rnaseq.config \\\n",
    "-resume\n",
    "\"\"\"\n",
    "print(nxf_cmd_align.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301f3b3a",
   "metadata": {},
   "source": [
    "#### 0.9 Clean up nextflow directories and remove fastqs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b217310b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove work directory and downloaded fastq files. \n",
    "\n",
    "shutil.rmtree(OUTPUT_DIR / \"work\")\n",
    "for fq in (OUTPUT_DIR / 'fetchngs_output' / 'fastq').glob('*.gz'):\n",
    "    fq.unlink()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
