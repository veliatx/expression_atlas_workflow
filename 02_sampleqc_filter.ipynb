{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QC Data and Filter Samples for DE testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pydeseq2.dds import DeseqDataSet\n",
    "import matplotlib.pyplot as plt\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "from IPython.display import HTML\n",
    "import html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CPUS = 8\n",
    "# DATA_PATH = '/data/expression_atlas/v1/GSE139358/'\n",
    "# DATA_PATH = '/data/expression_atlas/v1/GSE112087/'\n",
    "# DATA_PATH = '/data/expression_atlas/v1/GSE122459/'\n",
    "# DATA_PATH = '/data/expression_atlas/v1/GSE102371'\n",
    "# DATA_PATH = '/data/expression_atlas/v1/GSE110914/'\n",
    "DATA_PATH = '/data/expression_atlas/v1/GSE162828/'\n",
    "# DATA_PATH = '/data/expression_atlas/v1/GSE102371/'\n",
    "\n",
    "MULTIQC_PATH = os.path.join(DATA_PATH, 'rnaseq_output/multiqc/star_salmon/multiqc_report.html')\n",
    "\n",
    "#DATA_PATH = os.getcwd()\n",
    "COUNT_PATH = os.path.join(DATA_PATH, 'rnaseq_output/star_salmon')\n",
    "METADATA_FH = '' + '%s_metadata.csv' % DATA_PATH.rstrip('/').split('/')[-1]\n",
    "\n",
    "if not os.path.exists('results'):\n",
    "    os.mkdir('results')\n",
    "DDS_TRANSCRIPT_FH = '' + 'results/%s_dds_transcript.h5_ad' % DATA_PATH.rstrip('/').split('/')[-1]\n",
    "DDS_GENE_FH = '' + 'results/%s_dds_gene.h5_ad' % DATA_PATH.rstrip('/').split('/')[-1]\n",
    "\n",
    "TRANSCRIPT_SUM_FILTER = 10\n",
    "TRANSCRIPT_PSEUDOCOUNT = 0\n",
    "GENE_SUM_FILTER = 10\n",
    "GENE_PSEUDOCOUNT = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the MulitQC report into notebook. Note srcdoc was reqiured to get the html rendered without screwing up the \n",
    "# styling of the notebook while using an iframe. Buttons on the side don't work, but everything else seems to work fine.\n",
    "\n",
    "with open(MULTIQC_PATH,'r') as f_in:\n",
    "    html_raw = html.escape(f_in.read())\n",
    "\n",
    "HTML('<iframe srcdoc=\"%s\" width=\"1200px\" height=\"1000px\"></iframe>' % html_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read sample metadata into dataframe\n",
    "\n",
    "metadata = pd.read_csv(os.path.join('', METADATA_FH), index_col=0)\n",
    "smallest_condition_size = metadata[[c for c in metadata.columns if c.startswith('condition')]].value_counts()[-1]\n",
    "\n",
    "metadata, smallest_condition_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Merge dataframes from indiviudal runs into one expression dataframe\n",
    "\n",
    "# # Build the expression dataframe off of the first sample in the metadata dataframe\n",
    "# expression = pd.read_csv(os.path.join(COUNT_PATH, metadata.index[0], 'quant.sf'), delimiter= '\\t', index_col=0)\n",
    "# expression.drop(['Length','EffectiveLength','TPM'], inplace=True, axis=1)\n",
    "# expression.rename({'NumReads':metadata.index[0]}, inplace=True, axis=1)\n",
    "\n",
    "# expression_gene = pd.read_csv(os.path.join(COUNT_PATH, metadata.index[0], 'quant.genes.sf'), delimiter= '\\t', index_col=0)\n",
    "# expression_gene.drop(['Length','EffectiveLength','TPM'], inplace=True, axis=1)\n",
    "# expression_gene.rename({'NumReads':metadata.index[0]}, inplace=True, axis=1)\n",
    "\n",
    "# # Populate expression dataframe with remaining samples\n",
    "# for srx in tqdm(metadata.index[1:]):\n",
    "#     df = pd.read_csv(os.path.join(COUNT_PATH, srx, 'quant.sf'), delimiter='\\t', index_col=0)\n",
    "#     df.drop(['Length','EffectiveLength','TPM'], inplace=True, axis=1)\n",
    "#     df.rename({'NumReads':srx}, inplace=True, axis=1)\n",
    "#     expression = expression.merge(df, on='Name')\n",
    "\n",
    "#     df_gene = pd.read_csv(os.path.join(COUNT_PATH, srx, 'quant.genes.sf'), delimiter='\\t', index_col=0)\n",
    "#     df_gene.drop(['Length','EffectiveLength','TPM'], inplace=True, axis=1)\n",
    "#     df_gene.rename({'NumReads':srx}, inplace=True, axis=1)\n",
    "#     expression_gene = expression_gene.merge(df_gene, on='Name')\n",
    "\n",
    "# expression.shape, df.shape, expression_gene.shape, df_gene.shape\n",
    "\n",
    "\n",
    "# Read in transcript and gene dataframes\n",
    "\n",
    "expression = pd.read_csv(os.path.join(COUNT_PATH, 'salmon.merged.transcript_counts.tsv'), delimiter = '\\t', index_col=0)\n",
    "gene_transcript_mapping = expression[['gene_id']].copy().reset_index()\n",
    "expression.drop('gene_id', inplace=True, axis=1)\n",
    "\n",
    "tpm = pd.read_csv(os.path.join(COUNT_PATH, 'salmon.merged.transcript_tpm.tsv'), delimiter = '\\t', index_col=0)\n",
    "\n",
    "\n",
    "# See: https://nf-co.re/rnaseq/3.12.0/docs/output#salmon on output choice below \n",
    "# salmon.merged.gene_counts_length_scaled.tsv is the gene-level output of nf-core rnaseq that is bias-corrected\n",
    "# and is already scaled by potential transcript length\n",
    "expression_gene = pd.read_csv(os.path.join(COUNT_PATH, 'salmon.merged.gene_counts_length_scaled.tsv'), delimiter='\\t', index_col=0)\n",
    "expression_gene.drop('gene_name', inplace=True, axis=1)\n",
    "expression.shape, expression_gene.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter expression dataframe and prepare for QC/EDA.\n",
    "\n",
    "filtered_expression_transcript = expression.T.copy()\n",
    "filtered_expression_transcript = filtered_expression_transcript[\n",
    "                                    filtered_expression_transcript.columns[\n",
    "                                        filtered_expression_transcript.sum(axis=0) >= TRANSCRIPT_SUM_FILTER\n",
    "                                        ]\n",
    "                                    ]\n",
    "\n",
    "# Tag to take another look, filter later \n",
    "filtered_expression_transcript = filtered_expression_transcript[\n",
    "                                    filtered_expression_transcript.columns[\n",
    "                                        (filtered_expression_transcript >= TRANSCRIPT_SUM_FILTER).sum(axis=0) >\n",
    "                                            smallest_condition_size\n",
    "                                        ]\n",
    "                                    ]\n",
    "\n",
    "filtered_expression_gene = expression_gene.T.copy()\n",
    "filtered_expression_gene = filtered_expression_gene[\n",
    "                                    filtered_expression_gene.columns[\n",
    "                                        filtered_expression_gene.sum(axis=0) >= GENE_SUM_FILTER\n",
    "                                        ]\n",
    "                                    ]\n",
    "# Tag to take another look, filter later \n",
    "filtered_expression_gene = filtered_expression_gene[\n",
    "                                    filtered_expression_gene.columns[\n",
    "                                        (filtered_expression_gene >= GENE_SUM_FILTER).sum(axis=0) > \n",
    "                                            smallest_condition_size\n",
    "                                        ]\n",
    "                                    ]\n",
    "\n",
    "expression.shape, filtered_expression_transcript.shape, expression_gene.shape, filtered_expression_gene.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop specific samples from dataframe. Provide accession name of samples to remove from analysis.\n",
    "\n",
    "samples_to_drop = []\n",
    "# samples_to_drop = ['SRX3729696']\n",
    "# samples_to_drop = ['SRX9647190']\n",
    "filtered_expression_transcript.drop(samples_to_drop, axis=0, inplace=True)\n",
    "filtered_expression_gene.drop(samples_to_drop, axis=0, inplace=True)\n",
    "metadata.drop(samples_to_drop, axis=0, inplace=True)\n",
    "filtered_expression_transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop specific conditions/groups from metadata dataframe. \n",
    "\n",
    "samples_to_drop = []\n",
    "metadata.drop(samples_to_drop, axis=1, inplace=True)\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Deseq dataframe (AnnData object).\n",
    "\n",
    "# DeseqDataSet expects integers in counts matrix, need to check in on the default method for \n",
    "# rounding fractional counts to integers in tximport.\n",
    " \n",
    "dds = DeseqDataSet(\n",
    "    counts = filtered_expression_transcript.astype(int), \n",
    "    metadata = metadata, \n",
    "    design_factors = \n",
    "        [c for c in metadata.columns if c.startswith('group')]+\n",
    "        [c for c in metadata.columns if c.startswith('condition')],\n",
    "    refit_cooks = True, \n",
    "    n_cpus = NUM_CPUS, \n",
    "    )\n",
    "\n",
    "dds_gene = DeseqDataSet(\n",
    "    counts = filtered_expression_gene.astype(int), \n",
    "    metadata = metadata, \n",
    "    design_factors = \n",
    "        [c for c in metadata.columns if c.startswith('group')]+\n",
    "        [c for c in metadata.columns if c.startswith('condition')],\n",
    "    refit_cooks = True, \n",
    "    n_cpus = NUM_CPUS, \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set gene-transcript mapping attribute in uns for comparisons between \n",
    "# gene- and transcript-level quantifications.\n",
    "\n",
    "dds.uns['gene_transcript_mapping'] = gene_transcript_mapping\n",
    "dds_gene.uns['gene_transcript_mapping'] = gene_transcript_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute size-factors and library sizes.\n",
    "\n",
    "dds.fit_size_factors()\n",
    "dds.obs['size_factors'] = dds.obsm['size_factors']\n",
    "dds.obs['lib_sizes'] = dds.X.sum(axis=1)\n",
    "\n",
    "dds_gene.fit_size_factors()\n",
    "dds_gene.obs['size_factors'] = dds_gene.obsm['size_factors']\n",
    "dds_gene.obs['lib_sizes'] = dds_gene.X.sum(axis=1)\n",
    "\n",
    "dds.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance-stabilizing transformation.\n",
    "\n",
    "dds.vst()\n",
    "dds_gene.vst()\n",
    "\n",
    "dds.layers['vst_counts'], dds_gene.layers['vst_counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set recoverable count data.\n",
    "\n",
    "dds.layers['counts'] = dds.X.copy()\n",
    "dds_gene.layers['counts'] = dds_gene.X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute fractional counts to get a quick idea for any weird skews in library composition.\n",
    "\n",
    "dds.layers['fraction_counts'] = dds.layers['counts'] / np.reshape(dds.layers['counts'].sum(axis=1), (-1,1))\n",
    "dds_gene.layers['fraction_counts'] = dds_gene.layers['counts'] / np.reshape(dds_gene.layers['counts'].sum(axis=1), (-1,1))\n",
    "\n",
    "dds.layers['fraction_counts'], dds_gene.layers['fraction_counts']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CDF of fractional composition of libraries. \n",
    "\n",
    "ax = sns.ecdfplot(np.log2(dds.layers['fraction_counts'].T))\n",
    "ax.set_xlabel('log2 fraction counts')\n",
    "ax.legend(\n",
    "        labels=dds.obs.index, \n",
    "        loc='upper left', \n",
    "        bbox_to_anchor=(1.,1.), \n",
    "        ncols=1 if len(dds.obs.index) < 10 else int(len(dds.obs.index)/10),\n",
    "        frameon=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace count matrix with variance-transformed counts, following DESeq2 recommendation\n",
    "# for preprocessing count data before QC visualization.\n",
    "\n",
    "dds.X = dds.layers['vst_counts'].copy()\n",
    "dds_gene.X = dds_gene.layers['vst_counts'].copy()\n",
    "\n",
    "np.nan_to_num(dds.X, copy=False)\n",
    "np.nan_to_num(dds_gene.X, copy=False)\n",
    "\n",
    "dds.layers['counts'], dds.X, dds.layers['vst_counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale transformed variables.\n",
    "\n",
    "sc.pp.scale(dds)\n",
    "sc.pp.scale(dds_gene)\n",
    "\n",
    "np.nan_to_num(dds.X, copy=False)\n",
    "np.nan_to_num(dds_gene.X, copy=False)\n",
    "\n",
    "dds.X.mean(axis=0), dds.X.std(axis=0), dds_gene.X.mean(axis=0), dds_gene.X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminary PCA on transcript- and gene-level data.\n",
    "\n",
    "suffix_size = 4\n",
    "\n",
    "sc.pp.pca(dds)\n",
    "ax_transcript_pca = sc.pl.pca( \n",
    "    dds, \n",
    "    color=\n",
    "        [c for c in dds.obs.columns if c.startswith('group')]+\n",
    "        [c for c in dds.obs.columns if c.startswith('condition')], \n",
    "    size = 128,\n",
    "    show=False,\n",
    "    )\n",
    "\n",
    "for i, s in enumerate(dds.obsm['X_pca']):\n",
    "    if type(ax_transcript_pca) == list:\n",
    "        for ax in ax_transcript_pca:\n",
    "            ax.text(s[0], s[1], dds.obs.index[i][-suffix_size:])\n",
    "    else:\n",
    "        ax_transcript_pca.text(s[0], s[1], dds.obs.index[i][-suffix_size:])\n",
    "\n",
    "sc.pp.pca(dds_gene)\n",
    "ax_gene_pca = sc.pl.pca(\n",
    "    dds_gene, \n",
    "    color=\n",
    "        [c for c in dds_gene.obs.columns if c.startswith('group')]+\n",
    "        [c for c in dds_gene.obs.columns if c.startswith('condition')],\n",
    "    size = 128,\n",
    "    show=False, \n",
    "    )\n",
    "\n",
    "for i, s in enumerate(dds_gene.obsm['X_pca']):\n",
    "    if type(ax_gene_pca) == list:\n",
    "        for ax in ax_gene_pca:\n",
    "            ax.text(s[0], s[1], dds_gene.obs.index[i][-suffix_size:])\n",
    "    else:\n",
    "        ax_gene_pca.text(s[0], s[1], dds_gene.obs.index[i][-suffix_size:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot explained variance ratios.\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "ax[0].plot(dds.uns['pca']['variance_ratio'])\n",
    "ax[1].plot(dds_gene.uns['pca']['variance_ratio'])\n",
    "\n",
    "ax[0].set_ylabel('fraction explained variance')\n",
    "ax[0].set_xlabel('PC')\n",
    "ax[1].set_xlabel('PC')\n",
    "ax[0].set_title('Transcript')\n",
    "ax[1].set_title('Gene')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loadings for first 3 PCs\n",
    "\n",
    "sc.pl.pca_loadings(dds, components = '1,2,3')\n",
    "sc.pl.pca_loadings(dds_gene, components = '1,2,3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample-sample pearson correlation.\n",
    "\n",
    "dds.layers['vst_counts'].shape\n",
    "dds_gene.layers['vst_counts'].shape\n",
    "\n",
    "dist = np.corrcoef(np.nan_to_num(dds.layers['vst_counts'], copy=False))\n",
    "sns.heatmap(dist, xticklabels=dds.obs.index, yticklabels=dds.obs['condition-1'], cbar_kws={'label': 'pearson r'})\n",
    "plt.yticks(rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore the original counts data.\n",
    "\n",
    "dds.X = dds.layers['counts'].copy()\n",
    "dds_gene.X = dds_gene.layers['counts'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit dispersions, logFCs, and calculate cooks.\n",
    "\n",
    "dds.deseq2()\n",
    "dds_gene.deseq2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot fitted dispersions.\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "ax[0].scatter(\n",
    "        np.log(dds.varm['_normed_means']), \n",
    "        np.log(dds.varm['genewise_dispersions']), \n",
    "        s=1, \n",
    "        alpha=0.01, \n",
    "        label='raw',\n",
    "    )\n",
    "ax[0].scatter(\n",
    "        np.log(dds.varm['_normed_means']), \n",
    "        np.log(dds.varm['dispersions']), \n",
    "        s=1, \n",
    "        alpha=0.01, \n",
    "        label='squeezed',\n",
    "    )\n",
    "ax[0].scatter(\n",
    "        np.log(dds.varm['_normed_means']), \n",
    "        np.log(dds.varm['fitted_dispersions']), \n",
    "        s=1, \n",
    "        alpha=0.01, \n",
    "        label='trended', \n",
    "        c='r', \n",
    "    )\n",
    "ax[0].set_ylabel('log dispersions')\n",
    "ax[0].set_xlabel('log normalized mean')\n",
    "ax[0].set_title('transcript-level')\n",
    "ax[0].legend(frameon=False)\n",
    "legend = ax[0].legend(frameon=False)\n",
    "for lh in legend.legend_handles:\n",
    "    lh.set_alpha(1)\n",
    "\n",
    "ax[1].scatter(\n",
    "        np.log(dds_gene.varm['_normed_means']), \n",
    "        np.log(dds_gene.varm['genewise_dispersions']), \n",
    "        s=1, \n",
    "        alpha=0.01, \n",
    "        label='raw',\n",
    "    )\n",
    "ax[1].scatter(\n",
    "        np.log(dds_gene.varm['_normed_means']), \n",
    "        np.log(dds_gene.varm['dispersions']), \n",
    "        s=1, \n",
    "        alpha=0.01, \n",
    "        label='squeezed',\n",
    "    )\n",
    "ax[1].scatter(\n",
    "        np.log(dds_gene.varm['_normed_means']), \n",
    "        np.log(dds_gene.varm['fitted_dispersions']), \n",
    "        s=1, \n",
    "        alpha=0.01, \n",
    "        label='trended', \n",
    "        c='r', \n",
    "    )\n",
    "ax[1].set_xlabel('log normalized mean')\n",
    "ax[1].set_title('gene-level')\n",
    "legend = ax[1].legend(frameon=False)\n",
    "for lh in legend.legend_handles:\n",
    "    lh.set_alpha(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write dds objects to files for DE and LogFC calculations.\n",
    "\n",
    "# Pydeseq2 supports trend_coeffs/replaced as either np.array or pd.series, np.array required for \n",
    "# saving h5-formatted AnnData objects.\n",
    "dds.uns['trend_coeffs'] = np.array(dds.uns['trend_coeffs'])\n",
    "dds_gene.uns['trend_coeffs'] = np.array(dds_gene.uns['trend_coeffs'])\n",
    "\n",
    "dds.varm['replaced'] = np.array(dds.varm['replaced'])\n",
    "dds_gene.varm['replaced'] = np.array(dds_gene.varm['replaced'])\n",
    "\n",
    "# DeseqDataSet doesn't have native support for writing h5, save as AnnData objects and restore from\n",
    "# AnnData objects.\n",
    "\n",
    "dds.write(DDS_TRANSCRIPT_FH)\n",
    "dds_gene.write(DDS_GENE_FH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
