{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Sample Sheets and Define Groups/Conditions\n",
    "* User input needed:\n",
    "    * Define functions, condition levels, and group levels in cell below.\n",
    "    * Define specific samples to drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions, condition levels, and group levels in metadata dataframe.\n",
    "* Description of required metadata columns to be defined in SAMPLE_CONDITIONS:\n",
    "    * sample_type_1 -> description of primary designation of cell type, tissue, etc.\n",
    "        * Ex.:\n",
    "            * BLOOD, PBMC, SYNOVIUM, ILEUM...\n",
    "    * sample_type_* -> secondary description of designation of cell type, tissue, etc.\n",
    "       * Ex.:\n",
    "           * Subdivided tissues, etc.\n",
    "    * disease_* -> description of related disease for each sample. \n",
    "        * Ex.:\n",
    "            * SYSTEMIC_LUPUS_ERYTHEMATOSUS, RHEUMATOID_ARTHRITIS, SJOGRENS_SYNDROME, ULCERATIVE_COLITIIS, NA(if multiple diseases)...\n",
    "    * sample_condition_* -> description of condition (HEALTHY/DISEASE) for each sample\n",
    "        * sample_condition_1 -> primary disease phenotype ex. SLE, RA, T1D, etc.\n",
    "        * Meant to be partially redundant with below, where below conditions are used to create design matrix, and this is stored as metadata.\n",
    "    * condition_* -> description of condition (HEALTHY/DISEASE) for each sample\n",
    "        * condition_1 -> primary disease phenotype, ex. SLE, RA, T1D, T2D, etc.\n",
    "        * condition_* -> SNPs, drug treatments, etc.\n",
    "* Description of variables that need to be set in below cell for creating design matrix:\n",
    "    * SRX_COLUMN -> the SRX accession is usually present in 'experiment_accession' column, but sometimes present in 'run_accession' column depending on project.\n",
    "    * SAMPLE_CONDITION_COLUMNS -> dictionary with key='condition_name' and value='column to search for different condition levels'.\n",
    "    * SAMPLE_GROUP_COLUMNS -> similar to above, dictionary with key='group_name' and value='column to search for different group levels'.\n",
    "    * SAMPLE_CONDITIONS -> dictionary of dictionaries, with outer key='condition_name', inner key='string or pattern to search for in cell', and inner value='condition level to set'.\n",
    "    * SAMPLE_GROUPS -> dictionary of dictionaries, with outer key='group_name', inner key='string or patter to search for in cell', and inner value='group level to set'.\n",
    "* Description of functions that need to be configured in below cell:\n",
    "    * filter_conditon -> described in docstring.\n",
    "    * filter_group -> described in docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_PATH = '/data/expression_atlas/runs/%s/' % os.getcwd().split('/')[-1]\n",
    "\n",
    "RESULTS_PATH = DATA_PATH + 'de_results/%s' % DATA_PATH.rstrip('/').split('/')[-1]\n",
    "\n",
    "if not os.path.exists(DATA_PATH+'de_results'):\n",
    "    os.mkdir(DATA_PATH+'de_results')\n",
    "\n",
    "METADATA_FH = DATA_PATH + os.getcwd().split('/')[-1] + '_metadata.csv'\n",
    "\n",
    "# Define functions, condition levels, and group levels in metadata dataframe.\n",
    "SRX_COLUMN = 'experiment_accession'\n",
    "\n",
    "# Example setup for SAMPLE_CONDITION, SAMPLE_CONDITION_COLUMNS, etc.\n",
    "\n",
    "# SAMPLE_CONDITION_COLUMNS = {\n",
    "#     'condition-1': 'sample_description',\n",
    "#     'sample_type_1': 'sample_description',\n",
    "#     'disease_1': 'sample_description',\n",
    "#     'sample_condition_1': 'sample_description',\n",
    "#     'sample_condition_2': 'sample_description',\n",
    "#     }\n",
    "\n",
    "# SAMPLE_GROUP_COLUMNS = {\n",
    "#     }\n",
    "\n",
    "# SAMPLE_CONDITIONS = {\n",
    "#     'condition-1' : { \n",
    "#         'DR': 'DISEASE_1',\n",
    "#         'DM': 'DISEASE_1',\n",
    "#         'Control': 'CONTROL',\n",
    "#         },\n",
    "#     'sample_type_1' : {\n",
    "#         '':'PBMC',\n",
    "#         },\n",
    "#     'sample_condition_2': {\n",
    "#         'DR': 'TYPE_2_DIABETES_RETINOPATHY',\n",
    "#         'DM': 'TYPE_2_DIABETES_MELLITUS',\n",
    "#         'Control': 'HEALTHY',\n",
    "#         },\n",
    "#     'sample_condition_1': {\n",
    "#         'DR': 'TYPE_2_DIABETES',\n",
    "#         'DM': 'TYPE_2_DIABETES',\n",
    "#         'Control': 'HEALTHY',\n",
    "#         },\n",
    "#     'disease_1' : {\n",
    "#         'DR':'TYPE_2_DIABETES',\n",
    "#         'DM':'TYPE_2_DIABETES',\n",
    "#         'Control':'TYPE_2_DIABETES',\n",
    "#         },\n",
    "#     }\n",
    "\n",
    "\n",
    "# SAMPLE_GROUPS = {\n",
    "#     }\n",
    "\n",
    "# List of columns to keep in metadata file.\n",
    "KEEP_COLUMNS = [ \n",
    "            'single_end', \n",
    "            'strandedness', \n",
    "            'experiment_accession', \n",
    "            'submission_accession', \n",
    "            'library_layout', \n",
    "            'library_selection', \n",
    "            'library_source', \n",
    "            'library_strategy', \n",
    "            'library_name', \n",
    "            'instrument_model', \n",
    "            'instrument_platform', \n",
    "            'read_count', \n",
    "            'tax_id', \n",
    "            'sample_title', \n",
    "            'experiment_title', \n",
    "            'sample_description',\n",
    "        ]\n",
    "\n",
    "def filter_condition(cell: str, condition_key: str) -> bool:\n",
    "    '''Modify to check for a key present in SAMPLE_CONDITION\n",
    "\n",
    "    Args:\n",
    "        cell (str) contents of single cell from metadata dataframe\n",
    "        condition_key (str) key to search cell \n",
    "\n",
    "    Returns:\n",
    "        (bool) transfer key to cell\n",
    "    '''\n",
    "    # return cell.startswith(condition_key)\n",
    "    return condition_key in cell\n",
    "    # return cell.endswith(condition_key)\n",
    "\n",
    "def filter_group(cell: str, group_key: str) -> bool:\n",
    "    '''Modify to check for key present in SAMPLE_GROUP\n",
    "\n",
    "    Args:\n",
    "        cell (str) contents of single cell from metadata dataframe\n",
    "        group_key (str) key to search cell\n",
    "\n",
    "    Returns:\n",
    "        (bool) transfer key to cell\n",
    "    '''\n",
    "    #return cell.startswith(group_key)\n",
    "    return group_key in cell\n",
    "    # return cell.endswith(group_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read output of nf-core RNA-seq samplesheet into dataframe\n",
    "\n",
    "samplesheet_valid = pd.read_csv(os.path.join(DATA_PATH, 'rnaseq_output/pipeline_info/samplesheet.valid.csv'))\n",
    "samplesheet_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge run_table into samplesheet_valid if extra metadata from run_table is needed.\n",
    "\n",
    "# run_table = pd.read_csv(os.path.join(DATA_PATH, 'rnaseq_output/pipeline_info/SraRunTable.txt'))\n",
    "# run_table\n",
    "# samplesheet_valid = samplesheet_valid.merge(\n",
    "#     run_table.loc[:,['Run',]].rename(\n",
    "#         {'Run': 'run_accession'},\n",
    "#         axis=1,\n",
    "#     ), \n",
    "#     on='run_accession',\n",
    "# )\n",
    "# samplesheet_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop samples from metadata.\n",
    "* Samples are dropped based on \"SRX\" id in metadata dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter out samples that aren't desired in further analysis.\n",
    "\n",
    "samples_to_remove = []\n",
    "\n",
    "sample_indices = samplesheet_valid[samplesheet_valid[SRX_COLUMN].isin(samples_to_remove)].index\n",
    "\n",
    "sample_indices\n",
    "samplesheet_valid.drop(sample_indices, axis=0, inplace=True)\n",
    "\n",
    "samplesheet_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Match sample conditions and groups to those in SAMPLE_CONDITION_PREFIXES and SAMPLE_GROUP_PREFIXES \n",
    "\n",
    "for k, v in SAMPLE_CONDITION_COLUMNS.items():\n",
    "    samplesheet_valid[k] = np.nan\n",
    "    for kg, vg in SAMPLE_CONDITIONS[k].items():\n",
    "        samplesheet_valid.loc[samplesheet_valid[v].map(lambda x: filter_condition(x, kg)), k] = vg\n",
    "    try:\n",
    "        assert not samplesheet_valid[k].isnull().any()\n",
    "    except Exception as e:\n",
    "        print(k, v, samplesheet_valid[k])\n",
    "        raise e\n",
    "\n",
    "\n",
    "for k, v in SAMPLE_GROUP_COLUMNS.items():\n",
    "    samplesheet_valid[k] = np.nan\n",
    "    for kg, vg in SAMPLE_GROUPS[k].items():\n",
    "        samplesheet_valid.loc[samplesheet_valid[v].map(lambda x: filter_group(x, kg)), k] = vg\n",
    "    try:\n",
    "        assert not samplesheet_valid[k].isnull().any()\n",
    "    except Exception as e:\n",
    "        print(k, v, samplesheet_valid[k])\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save metadata to csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Push metadata to csv. \n",
    "\n",
    "metadata = samplesheet_valid[\n",
    "                        [SRX_COLUMN] + \n",
    "                        list(SAMPLE_CONDITIONS.keys()) + \n",
    "                        list(SAMPLE_GROUPS.keys()) + \n",
    "                        [c for c in KEEP_COLUMNS if c != SRX_COLUMN]\n",
    "                    ].copy()\n",
    "\n",
    "metadata.rename({SRX_COLUMN: 'accession'}, inplace=True, axis=1)\n",
    "\n",
    "\n",
    "# Collapse technical replicates into eachother by summing read counts across runs.\n",
    "if 'read_count' in metadata.columns:\n",
    "    metadata['read_count'] = metadata.groupby('accession')['read_count'].transform('sum')\n",
    "\n",
    "# Sample dataframe from output of nf-core rnaseq lists distinct samples by SRR*, \n",
    "# but groups samples by SRX* for analysis.\n",
    "metadata.drop_duplicates(inplace=True)\n",
    "\n",
    "single_groups = []\n",
    "for c in metadata.columns:\n",
    "    if not c.startswith('group') or c.startswith('condition'):\n",
    "        continue\n",
    "    if len(metadata[c].value_counts()) == 1:\n",
    "        single_groups.append(c)\n",
    "\n",
    "metadata.drop(single_groups, axis=1, inplace=True)\n",
    "\n",
    "metadata.to_csv(METADATA_FH, index=False)\n",
    "metadata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydeseq2",
   "language": "python",
   "name": "pydeseq2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
