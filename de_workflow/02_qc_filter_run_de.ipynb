{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Quality Control, Filtering and Differential Expression Analysis\n",
    "\n",
    "This notebook performs quality control checks, filters samples, and runs differential expression testing on RNA-seq data.\n",
    "\n",
    "###  Required User Input\n",
    "\n",
    "1. Define Contrasts for Differential Expression Analysis\n",
    "    - You must specify the contrasts you want to analyze in the format: \n",
    "        - *contrasts = {\n",
    "            'CONTRAST_NAME': ['column_name', 'treatment_level', 'reference_level']\n",
    "        }*\n",
    "    - **Important**: The notebook will not complete if:\n",
    "        - Contrasts are not defined\n",
    "        - Contrast levels don't exist in the metadata CSV\n",
    "\n",
    "2. Define Samples/Groups to Drop\n",
    "    - Optionally specify any samples or groups that should be excluded from the analysis:\n",
    "        - Individual samples can be dropped by their accession ID\n",
    "        - Entire groups can be dropped based on their group designation\n",
    "\n",
    "#### Workflow Overview\n",
    "1. Load and prepare data\n",
    "2. Perform quality control checks\n",
    "3. Filter samples based on user criteria\n",
    "4. Run differential expression analysis\n",
    "5. Generate visualizations and statistics\n",
    "\n",
    "#### Expected Input Files\n",
    "1. MultiQC Report\n",
    "   - Location: `rnaseq_output/multiqc/star_salmon/multiqc_report.html`\n",
    "   - Generated by nf-core/rnaseq pipeline\n",
    "\n",
    "2. Salmon Quantification Files\n",
    "   - Location: `rnaseq_output/star_salmon/`\n",
    "   - Files per sample:\n",
    "     - `quant.sf` - Transcript-level quantification\n",
    "     - `quant.genes.sf` - Gene-level quantification\n",
    "\n",
    "3. Merged Expression Files\n",
    "   - Location: `rnaseq_output/star_salmon/`\n",
    "   - Files:\n",
    "     - `salmon.merged.transcript_counts.tsv` - Merged transcript counts\n",
    "     - `salmon.merged.transcript_tpm.tsv` - Merged transcript TPMs\n",
    "     - `salmon.merged.gene_counts_length_scaled.tsv` - Merged gene counts (length-scaled)\n",
    "     - `salmon.merged.gene_tpm.tsv` - Merged gene TPMs\n",
    "\n",
    "4. Metadata File\n",
    "   - Location: `de_results/{EXPERIMENT_ID}_metadata.csv`\n",
    "   - Required columns:\n",
    "     - Sample accession IDs as index\n",
    "     - At least one condition column (e.g., 'condition-1')\n",
    "     - Optional grouping columns (e.g., 'group-1')\n",
    "\n",
    "\n",
    "\n",
    "#### Output Files \n",
    "- AnnData objects with DE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "import os \n",
    "import warnings \n",
    "import html\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "from IPython.display import HTML\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pydeseq2.ds import DeseqStats\n",
    "from pydeseq2.dds import DeseqDataSet\n",
    "\n",
    "from src.utils import (\n",
    "    relevel_design, \n",
    "    likelihood_ratio_test,\n",
    "    pca_anova_model, \n",
    "    pca_variance_components_model,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Configure Notebook \n",
    "\n",
    "#### Required Variable Definitions:\n",
    "Notebook Paths/Parameters:\n",
    "- *NUM_CPUS*: Number of CPUs to use for parallel processing\n",
    "- *DATA_PATH*: Root directory path for the project\n",
    "- *MULTIQC_PATH*: Path to MultiQC report from nf-core/rnaseq pipeline\n",
    "- *COUNT_PATH*: Directory containing Salmon quantification files\n",
    "- *RESULTS_PATH*: Output directory for differential expression results\n",
    "- *METADATA_FH*: Path to metadata CSV file containing sample information\n",
    "- *PCA_VARIABLES*: Variables to color PCA plots by\n",
    "- *DDS_TRANSCRIPT_FH*: Path to save transcript-level DESeq2 dataset object\n",
    "- *DDS_GENE_FH*: Path to save gene-level DESeq2 dataset object\n",
    "\n",
    "Analysis Parameters:\n",
    "- *MAX_NLOG10_PADJ*: Maximum -log10 adjusted p-value to prevent infinity (default: 400)\n",
    "- *TRANSCRIPT_SUM_FILTER*: Minimum sum of counts to keep a transcript (default: 1)\n",
    "    - Should be set low for experiments where lowly-expressed receptors are of interest\n",
    "- *GENE_SUM_FILTER*: Minimum sum of counts to keep a gene (default: 1)\n",
    "    - Should be set low for experiments where lowly-expressed receptors are of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CPUS = 8\n",
    "\n",
    "DATA_PATH = Path.cwd().parent\n",
    "\n",
    "EXPERIMENT_ID = DATA_PATH.parts[-1]\n",
    "\n",
    "MULTIQC_PATH = DATA_PATH / 'rnaseq_output/multiqc/star_salmon/multiqc_report.html'\n",
    "\n",
    "COUNT_PATH = DATA_PATH / 'rnaseq_output/star_salmon'\n",
    "\n",
    "RESULTS_PATH = DATA_PATH / 'de_results'\n",
    "\n",
    "METADATA_FH = RESULTS_PATH / f'{EXPERIMENT_ID}_metadata.csv'\n",
    "\n",
    "PCA_VARIABLES = ['lib_sizes', 'library_layout', 'instrument_model']\n",
    "\n",
    "DDS_TRANSCRIPT_FH = RESULTS_PATH / f'{EXPERIMENT_ID}_dds_transcript.h5_ad'\n",
    "DDS_GENE_FH = RESULTS_PATH / f'{EXPERIMENT_ID}_dds_gene.h5_ad'\n",
    "\n",
    "MAX_NLOG10_PADJ = 400.\n",
    "TRANSCRIPT_SUM_FILTER = 1\n",
    "GENE_SUM_FILTER = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 MultiQC output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the MulitQC report into notebook. Note srcdoc was reqiured to get the html rendered without screwing up the \n",
    "# styling of the notebook while using an iframe. Buttons on the side don't work, but everything else seems to work fine.\n",
    "\n",
    "with open(MULTIQC_PATH,'r') as f_in:\n",
    "    html_raw = html.escape(f_in.read())\n",
    "\n",
    "HTML(f'<iframe srcdoc=\"{html_raw}\" width=\"1200px\" height=\"1000px\"></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read sample metadata into dataframe\n",
    "\n",
    "metadata = pd.read_csv(METADATA_FH, index_col=0)\n",
    "smallest_condition_size = metadata.loc[\n",
    "    :,[metadata.columns.str.startswith('condition')]\n",
    "].value_counts()[-1]\n",
    "\n",
    "metadata, smallest_condition_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Define Contrasts\n",
    "\n",
    "Contrasts must be defined in a dictionary with the following format:\n",
    "\n",
    "*contrasts = {\n",
    "    'CONTRAST_NAME': ['column_name', 'treatment_level', 'reference_level']\n",
    "}*\n",
    "\n",
    "**Requirements:**\n",
    "- Column name must exist in metadata DataFrame\n",
    "- Treatment and reference levels must exist in the specified column\n",
    "- Underscores in levels will be automatically replaced with hyphens\n",
    "\n",
    "**Example:**\n",
    "*contrasts = {\n",
    "    'TYPE_2_DIABETES_vs_CONTROL': ['condition-1', 'DISEASE-1', 'CONTROL']\n",
    "}*\n",
    "\n",
    "Each contrast will generate a DE results DataFrame stored in:\n",
    "- *anndata.uns['stat_results'][<contrast_name>]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually define contrasts given conditions in metadata dataframe. Define reference level for comparisons.\n",
    "\n",
    "\n",
    "# Pydeseq2 contrasts require condition-name, treatment level, reference level format.\n",
    "\n",
    "# Example contrast:\n",
    "# contrasts = {\n",
    "#     'TYPE_2_DIABETES_vs_CONTROL': ['condition-1','DISEASE-1', 'CONTROL'],\n",
    "#     }\n",
    "\n",
    "reference_level = ['condition-1', 'CONTROL']\n",
    "\n",
    "# All underscores are replaced by hyphens.\n",
    "assert (len(contrasts) > 0), \"No contrasts defined\"\n",
    "assert all(c[0] in metadata.columns for c in contrasts.values()), \"Column not found in metadata\" \n",
    "assert all(\n",
    "    (   \n",
    "        l_1.replace('-','_') in metadata[c].values and \n",
    "        l_2.replace('-','_') in metadata[c].values\n",
    "    ) for c, l_1, l_2 in contrasts.values()\n",
    "), \"Treatment or reference level not found in metadata\"\n",
    "\n",
    "# Convert underscores to hyphens to adhere to pydeseq2 requirements\n",
    "reference_level = [r.replace('_','-') for r in reference_level]\n",
    "contrasts = {\n",
    "    n: [r.replace('_','-') for r in l] for n, l in contrasts.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge effective lengths and average across all runs for transcript and gene dataframes.\n",
    "\n",
    "# Build the transcript length dataframe off of the first sample in the metadata dataframe.\n",
    "transcript_length = pd.read_csv(\n",
    "    COUNT_PATH / metadata.index[0] / 'quant.sf',\n",
    "    delimiter='\\t',\n",
    "    index_col=0,\n",
    ")\n",
    "transcript_length.rename({'EffectiveLength':f'EffectiveLength_{metadata.index[0]}'}, axis=1, inplace=True)\n",
    "transcript_length.drop(['Length', 'TPM', 'NumReads'], inplace=True, axis=1)\n",
    "\n",
    "gene_length = pd.read_csv(\n",
    "    COUNT_PATH / metadata.index[0] / 'quant.genes.sf',\n",
    "    delimiter='t',\n",
    "    index_col=0,\n",
    ")\n",
    "gene_length.rename({'EffectiveLength':f'EffectiveLength_{metadata.index[0]}'}, axis=1, inplace=True)\n",
    "gene_length.drop(['Length', 'TPM', 'NumReads'], inplace=True, axis=1)\n",
    "\n",
    "# Populate samples into effective length dataframe with remaining samples.\n",
    "for srx in tqdm(metadata.index[1:]):\n",
    "    df = pd.read_csv(\n",
    "        COUNT_PATH / metadata.index[0] / 'quant.sf',\n",
    "        delimiter='\\t',\n",
    "        index_col=0,\n",
    "    )\n",
    "    df.drop(['Length', 'TPM', 'NumReads'], inplace=True, axis=1)\n",
    "    df.rename({'EffectiveLength':f'EffectiveLength_{srx}'}, axis=1, inplace=True)\n",
    "    transcript_length = transcript_length.merge(df, on='Name')\n",
    "\n",
    "    df_gene = pd.read_csv(os.path.join(COUNT_PATH, srx, 'quant.genes.sf'), delimiter='\\t', index_col=0)\n",
    "    df_gene.drop(['Length', 'TPM', 'NumReads'], inplace=True, axis=1)\n",
    "    df_gene.rename({'EffectiveLength':f'EffectiveLength_{srx}'}, axis=1, inplace=True)\n",
    "    gene_length = gene_length.merge(df_gene, on='Name')\n",
    "\n",
    "\n",
    "# Average effective lengths.\n",
    "transcript_length['length'] = transcript_length.mean(axis=1)\n",
    "gene_length['length'] = gene_length.mean(axis=1)\n",
    "transcript_length.drop([c for c in transcript_length.columns if c.startswith('EffectiveLength_')], inplace=True, axis=1)\n",
    "gene_length.drop([c for c in gene_length.columns if c.startswith('EffectiveLength_')], inplace=True, axis=1)\n",
    "\n",
    "transcript_length.shape, gene_length.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in transcript and gene count/TPM dataframes.\n",
    "\n",
    "expression = pd.read_csv(\n",
    "    COUNT_PATH / 'salmon.merged.transcript_counts.tsv', \n",
    "    delimiter = '\\t', \n",
    "    index_col=0,\n",
    ")\n",
    "gene_transcript_mapping = expression.loc[:,['gene_id']].reset_index()\n",
    "expression.drop('gene_id', inplace=True, axis=1)\n",
    "\n",
    "tpm = pd.read_csv(\n",
    "    COUNT_PATH / 'salmon.merged.transcript_tpm.tsv', \n",
    "    delimiter = '\\t', \n",
    "    index_col=0,\n",
    ")\n",
    "tpm.drop('gene_id', inplace=True, axis=1)\n",
    "\n",
    "# See: https://nf-co.re/rnaseq/3.12.0/docs/output#salmon on output choice below \n",
    "# salmon.merged.gene_counts_length_scaled.tsv is the gene-level output of nf-core rnaseq that is bias-corrected\n",
    "# and is already scaled by potential transcript length\n",
    "expression_gene = pd.read_csv(\n",
    "    COUNT_PATH / 'salmon.merged.gene_counts_length_scaled.tsv', \n",
    "    delimiter='\\t', \n",
    "    index_col=0,\n",
    ")\n",
    "expression_gene.drop('gene_name', inplace=True, axis=1)\n",
    "\n",
    "tpm_gene = pd.read_csv(\n",
    "    COUNT_PATH / 'salmon.merged.gene_tpm.tsv', \n",
    "    delimiter='\\t', \n",
    "    index_col=0,\n",
    ")\n",
    "tpm_gene.drop('gene_name', inplace=True, axis=1)\n",
    "\n",
    "expression.shape, expression_gene.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter expression dataframes on samples not in metadata.csv\n",
    "\n",
    "samples_to_drop = [c for c in expression.columns if c not in metadata.index]\n",
    "\n",
    "expression.drop(samples_to_drop, axis=1, inplace=True)\n",
    "expression_gene.drop(samples_to_drop, axis=1, inplace=True)\n",
    "tpm.drop(samples_to_drop, axis=1, inplace=True)\n",
    "tpm_gene.drop(samples_to_drop, axis=1, inplace=True)\n",
    "expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Drop samples or groups from count dataframe or design matrix, respectively.\n",
    "* Samples are dropped based on \"SRX\" id, or cell in 'accession' column of the metadata dataframe.\n",
    "* Groups are dropped based on group id ex. 'group-1', a grouping present in the metadata dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop specific samples from dataframe. Provide accession name of samples to remove from analysis.\n",
    "\n",
    "# Clear outlier.\n",
    "samples_to_drop = []\n",
    "\n",
    "expression.drop(samples_to_drop, axis=1, inplace=True)\n",
    "expression_gene.drop(samples_to_drop, axis=1, inplace=True)\n",
    "tpm.drop(samples_to_drop, axis=1, inplace=True)\n",
    "tpm_gene.drop(samples_to_drop, axis=1, inplace=True)\n",
    "metadata.drop(samples_to_drop, axis=0, inplace=True)\n",
    "\n",
    "# Drop specific conditions/groups from metadata dataframe. \n",
    "\n",
    "groups_to_drop = []\n",
    "metadata.drop(groups_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter expression dataframe and prepare for QC/EDA.\n",
    "\n",
    "# Filter and prepare transcript-level expression data\n",
    "filtered_expression_transcript = expression.T.copy()\n",
    "filtered_expression_transcript = filtered_expression_transcript.loc[\n",
    "    :,filtered_expression_transcript.sum(axis=0) >= TRANSCRIPT_SUM_FILTER\n",
    "]\n",
    "filtered_expression_transcript = filtered_expression_transcript.loc[\n",
    "    :,(filtered_expression_transcript >= TRANSCRIPT_SUM_FILTER).sum(axis=0) > smallest_condition_size\n",
    "]\n",
    "\n",
    "# Filter corresponding transcript TPMs\n",
    "filtered_tpm_transcript = tpm.T.copy()\n",
    "filtered_tpm_transcript = filtered_tpm_transcript.loc[:, filtered_expression_transcript.columns]\n",
    "\n",
    "# Filter and prepare gene-level expression data\n",
    "filtered_expression_gene = expression_gene.T.copy()\n",
    "filtered_expression_gene = filtered_expression_gene.loc[\n",
    "    :, filtered_expression_gene.sum(axis=0) >= GENE_SUM_FILTER\n",
    "]\n",
    "filtered_expression_gene = filtered_expression_gene.loc[\n",
    "    :, (filtered_expression_gene >= GENE_SUM_FILTER).sum(axis=0) > smallest_condition_size\n",
    "]\n",
    "\n",
    "# Filter corresponding gene TPMs\n",
    "filtered_tpm_gene = tpm_gene.T.copy()\n",
    "filtered_tpm_gene = filtered_tpm_gene[filtered_expression_gene.columns]\n",
    "\n",
    "# Verify alignment of all filtered datasets\n",
    "assert all([\n",
    "    filtered_expression_gene.columns.equals(filtered_tpm_gene.columns),\n",
    "    filtered_expression_transcript.columns.equals(filtered_tpm_transcript.columns),\n",
    "    filtered_expression_gene.index.equals(filtered_tpm_gene.index),\n",
    "    filtered_expression_transcript.index.equals(filtered_tpm_transcript.index)\n",
    "]), \"Misaligned indices or columns in filtered datasets\"\n",
    "\n",
    "# Shapes of original and filtered datasets\n",
    "\n",
    "(   expression.shape, \n",
    "    filtered_expression_transcript.shape, \n",
    "    expression_gene.shape, \n",
    "    filtered_expression_gene.shape, \n",
    "    filtered_tpm_transcript.shape, \n",
    "    filtered_tpm_gene.shape, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Build DeseqDataSet objects from gene and transcript data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Deseq dataframe (AnnData object).\n",
    "\n",
    "# DeseqDataSet expects integers in counts matrix, need to check in on the default method for \n",
    "# rounding fractional counts to integers in tximport.\n",
    " \n",
    "dds = DeseqDataSet(\n",
    "    counts = filtered_expression_transcript.astype(int), \n",
    "    metadata = metadata, \n",
    "    design_factors = (\n",
    "        [c for c in metadata.columns if c.startswith('group')]+\n",
    "        [c for c in metadata.columns if c.startswith('condition')]\n",
    "    ),\n",
    "    ref_level=reference_level,\n",
    "    refit_cooks = True, \n",
    "    n_cpus = NUM_CPUS, \n",
    ")\n",
    "\n",
    "dds_gene = DeseqDataSet(\n",
    "    counts = filtered_expression_gene.astype(int), \n",
    "    metadata = metadata, \n",
    "    design_factors = (\n",
    "        [c for c in metadata.columns if c.startswith('group')]+\n",
    "        [c for c in metadata.columns if c.startswith('condition')]\n",
    "    ),\n",
    "    ref_level=reference_level,\n",
    "    refit_cooks = True, \n",
    "    n_cpus = NUM_CPUS, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set gene-transcript mapping attribute in uns for comparisons between \n",
    "# gene- and transcript-level quantifications.\n",
    "\n",
    "dds.uns['gene_transcript_mapping'] = gene_transcript_mapping\n",
    "dds_gene.uns['gene_transcript_mapping'] = gene_transcript_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set raw TPMs as layer in dds objects.\n",
    "\n",
    "dds.layers['raw_tpm'] = np.array(filtered_tpm_transcript)\n",
    "dds_gene.layers['raw_tpm'] = np.array(filtered_tpm_gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the average effective lengths into the var dataframe.\n",
    "\n",
    "dds.var = dds.var.merge(transcript_length, left_index=True, right_index=True)\n",
    "dds_gene.var = dds_gene.var.merge(gene_length, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Compute size-factors, library sizes, and perform vst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute size-factors and library sizes.\n",
    "\n",
    "dds.fit_size_factors()\n",
    "dds.obs['size_factors'] = dds.obsm['size_factors']\n",
    "dds.obs['lib_sizes'] = dds.X.sum(axis=1)\n",
    "\n",
    "dds_gene.fit_size_factors()\n",
    "dds_gene.obs['size_factors'] = dds_gene.obsm['size_factors']\n",
    "dds_gene.obs['lib_sizes'] = dds_gene.X.sum(axis=1)\n",
    "\n",
    "dds.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance-stabilizing transformation.\n",
    "\n",
    "dds.vst()\n",
    "dds_gene.vst()\n",
    "\n",
    "# Set recoverable count data.\n",
    "\n",
    "dds.layers['counts'] = dds.X.copy()\n",
    "dds_gene.layers['counts'] = dds_gene.X.copy()\n",
    "\n",
    "# Compute fractional counts to get a quick idea for any weird skews in library composition.\n",
    "\n",
    "dds.layers['fraction_counts'] = dds.layers['counts'] / np.reshape(dds.layers['counts'].sum(axis=1), (-1,1))\n",
    "dds_gene.layers['fraction_counts'] = dds_gene.layers['counts'] / np.reshape(dds_gene.layers['counts'].sum(axis=1), (-1,1))\n",
    "\n",
    "dds.layers['fraction_counts'], dds_gene.layers['fraction_counts']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 CDF curves library composition by fraction counts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CDF of fractional composition of libraries. \n",
    "\n",
    "ax_transcript = sns.ecdfplot(np.log2(dds.layers['fraction_counts'].T))\n",
    "ax_transcript.set_xlabel('log2 fraction counts')\n",
    "ax_transcript.legend(\n",
    "    labels=dds.obs.index, \n",
    "    loc='upper left', \n",
    "    bbox_to_anchor=(1.,1.), \n",
    "    ncols=1 if len(dds.obs.index) < 10 else int(len(dds.obs.index)/10),\n",
    "    frameon=False,\n",
    ")\n",
    "ax_transcript.set_title('transcript')\n",
    "plt.show()\n",
    "\n",
    "ax_gene = sns.ecdfplot(np.log2(dds_gene.layers['fraction_counts'].T))\n",
    "ax_gene.set_xlabel('log2 fraction counts')\n",
    "ax_gene.legend(\n",
    "    labels=dds_gene.obs.index, \n",
    "    loc='upper left', \n",
    "    bbox_to_anchor=(1.,1.), \n",
    "    ncols=1 if len(dds_gene.obs.index) < 10 else int(len(dds_gene.obs.index)/10),\n",
    "    frameon=False,\n",
    ")\n",
    "ax_gene.set_title('gene')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace count matrix with variance-transformed counts before QC and visualization. \n",
    "\n",
    "dds.X = dds.layers['vst_counts'].copy()\n",
    "dds_gene.X = dds_gene.layers['vst_counts'].copy()\n",
    "\n",
    "np.nan_to_num(dds.X, copy=False)\n",
    "np.nan_to_num(dds_gene.X, copy=False)\n",
    "\n",
    "# Scale transformed variables.\n",
    "\n",
    "sc.pp.scale(dds)\n",
    "sc.pp.scale(dds_gene)\n",
    "\n",
    "np.nan_to_num(dds.X, copy=False)\n",
    "np.nan_to_num(dds_gene.X, copy=False)\n",
    "\n",
    "dds.X.mean(axis=0), dds.X.std(axis=0), dds_gene.X.mean(axis=0), dds_gene.X.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.9 PCA on vst-counts colored on conditions, groups, and defined PCA variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminary PCA on transcript- and gene-level data.\n",
    "\n",
    "suffix_size = 4\n",
    "\n",
    "sc.pp.pca(dds)\n",
    "ax_transcript_pca = sc.pl.pca( \n",
    "    dds, \n",
    "    color=(\n",
    "        [c for c in dds.obs.columns if c.startswith('group')]+\n",
    "        [c for c in dds.obs.columns if c.startswith('condition')]+\n",
    "        ['lib_sizes', 'library_layout', 'instrument_model']\n",
    "    ), \n",
    "    size = 128,\n",
    "    show=False,\n",
    ")\n",
    "\n",
    "for i, s in enumerate(dds.obsm['X_pca']):\n",
    "    if isinstance(ax_transcript_pca, list):\n",
    "        for ax in ax_transcript_pca:\n",
    "            ax.text(s[0], s[1], dds.obs.index[i][-suffix_size:])\n",
    "    else:\n",
    "        ax_transcript_pca.text(s[0], s[1], dds.obs.index[i][-suffix_size:])\n",
    "\n",
    "sc.pp.pca(dds_gene)\n",
    "ax_gene_pca = sc.pl.pca(\n",
    "    dds_gene, \n",
    "    color=(\n",
    "        [c for c in dds_gene.obs.columns if c.startswith('group')]+\n",
    "        [c for c in dds_gene.obs.columns if c.startswith('condition')]+\n",
    "        ['lib_sizes', 'library_layout', 'instrument_model']\n",
    "    ), \n",
    "    size = 128,\n",
    "    show=False, \n",
    "    )\n",
    "\n",
    "for i, s in enumerate(dds_gene.obsm['X_pca']):\n",
    "    if isinstance(ax_gene_pca, list):\n",
    "        for ax in ax_gene_pca:\n",
    "            ax.text(s[0], s[1], dds_gene.obs.index[i][-suffix_size:])\n",
    "    else:\n",
    "        ax_gene_pca.text(s[0], s[1], dds_gene.obs.index[i][-suffix_size:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10 Plot additional PCs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PCA out to 4 PCs for transcript-level quantifcations. \n",
    "\n",
    "transcript_color_columns = [c for c in dds.obs.columns if c.startswith(('group', 'condition',))]+ \\\n",
    "    ['lib_sizes', 'library_layout', 'instrument_model']\n",
    "ax_transcript_pca = sc.pl.pca( \n",
    "    dds, \n",
    "    color=transcript_color_columns, \n",
    "    size = 128,\n",
    "    show=False,\n",
    "    ncols=len(transcript_color_columns),\n",
    "    components=['1,2', '2,3', '3,4', '4,5'],\n",
    ")\n",
    "\n",
    "gene_color_columns = [c for c in dds_gene.obs.columns if c.startswith(('group', 'condition',))]+ \\\n",
    "    ['lib_sizes', 'library_layout', 'instrument_model']\n",
    "ax_transcript_pca = sc.pl.pca( \n",
    "    dds_gene, \n",
    "    color=gene_color_columns, \n",
    "    size = 128,\n",
    "    show=False,\n",
    "    ncols=len(gene_color_columns),\n",
    "    components=['1,2', '2,3', '3,4', '4,5'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.11 PC - explained variance ratios. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot explained variance ratios.\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "ax[0].plot(dds.uns['pca']['variance_ratio'])\n",
    "ax[1].plot(dds_gene.uns['pca']['variance_ratio'])\n",
    "\n",
    "ax[0].set_ylabel('fraction explained variance')\n",
    "ax[0].set_xlabel('PC')\n",
    "ax[1].set_xlabel('PC')\n",
    "ax[0].set_title('Transcript')\n",
    "ax[1].set_title('Gene')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.12 PCA loadings for transcript(top) and gene(bottom)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loadings for first 3 PCs.\n",
    "\n",
    "sc.pl.pca_loadings(dds, components = '1,2,3')\n",
    "sc.pl.pca_loadings(dds_gene, components = '1,2,3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.13 Sample-Sample pearson correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample-sample pearson correlation.\n",
    "\n",
    "dds.layers['vst_counts'].shape\n",
    "dds_gene.layers['vst_counts'].shape\n",
    "\n",
    "dist = np.corrcoef(dds.layers['vst_counts'])\n",
    "\n",
    "ax_transcript = sns.heatmap(\n",
    "    dist, \n",
    "    xticklabels=dds.obs.index, \n",
    "    yticklabels=dds.obs['condition-1'], \n",
    "    cbar_kws={'label': 'pearson r'}, \n",
    ")\n",
    "ax_transcript.set_title('transcript')\n",
    "plt.show()\n",
    "\n",
    "dist = np.corrcoef(dds_gene.layers['vst_counts'])\n",
    "\n",
    "ax_gene = sns.heatmap(\n",
    "    dist, \n",
    "    xticklabels=dds_gene.obs.index, \n",
    "    yticklabels=dds_gene.obs['condition-1'], \n",
    "    cbar_kws={'label': 'pearson r'},\n",
    ")\n",
    "ax_gene.set_title('gene')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.14 Reset counts, fit dispersion estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore the original counts data.\n",
    "\n",
    "dds.X = dds.layers['counts'].copy()\n",
    "dds_gene.X = dds_gene.layers['counts'].copy()\n",
    "\n",
    "# Fit dispersions, logFCs, and calculate cooks.\n",
    "\n",
    "dds.deseq2()\n",
    "dds_gene.deseq2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.15 Plot fitted and squeezed dispersions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot fitted dispersions.\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "ax[0].scatter(\n",
    "    np.log(dds.varm['_normed_means']), \n",
    "    np.log(dds.varm['genewise_dispersions']), \n",
    "    s=1, \n",
    "    alpha=0.01, \n",
    "    label='raw',\n",
    ")\n",
    "ax[0].scatter(\n",
    "    np.log(dds.varm['_normed_means']), \n",
    "    np.log(dds.varm['dispersions']), \n",
    "    s=1, \n",
    "    alpha=0.01, \n",
    "    label='squeezed',\n",
    ")\n",
    "ax[0].scatter(\n",
    "    np.log(dds.varm['_normed_means']), \n",
    "    np.log(dds.varm['fitted_dispersions']), \n",
    "    s=1, \n",
    "    alpha=0.01, \n",
    "    label='trended', \n",
    "    c='r', \n",
    ")\n",
    "ax[0].set_ylabel('log dispersions')\n",
    "ax[0].set_xlabel('log normalized mean')\n",
    "ax[0].set_title('transcript-level')\n",
    "ax[0].legend(frameon=False)\n",
    "legend = ax[0].legend(frameon=False)\n",
    "for lh in legend.legend_handles:\n",
    "    lh.set_alpha(1)\n",
    "\n",
    "ax[1].scatter(\n",
    "    np.log(dds_gene.varm['_normed_means']), \n",
    "    np.log(dds_gene.varm['genewise_dispersions']), \n",
    "    s=1, \n",
    "    alpha=0.01, \n",
    "    label='raw',\n",
    ")\n",
    "ax[1].scatter(\n",
    "    np.log(dds_gene.varm['_normed_means']), \n",
    "    np.log(dds_gene.varm['dispersions']), \n",
    "    s=1, \n",
    "    alpha=0.01, \n",
    "    label='squeezed',\n",
    ")\n",
    "ax[1].scatter(\n",
    "    np.log(dds_gene.varm['_normed_means']), \n",
    "    np.log(dds_gene.varm['fitted_dispersions']), \n",
    "    s=1, \n",
    "    alpha=0.01, \n",
    "    label='trended', \n",
    "    c='r', \n",
    ")\n",
    "ax[1].set_xlabel('log normalized mean')\n",
    "ax[1].set_title('gene-level')\n",
    "legend = ax[1].legend(frameon=False)\n",
    "for lh in legend.legend_handles:\n",
    "    lh.set_alpha(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.16 Examine metadata and design matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dds.obsm['design_matrix']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.17 Fit model and run DE tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Stats object. Define relevant contrasts for DE and LogFC computations and run tests. \n",
    "\n",
    "# Holds all DeseqStats objects as defined in contrasts.\n",
    "dds.uns['stat_results'] = {}\n",
    "dds_gene.uns['stat_results'] = {}\n",
    "\n",
    "for k, v in contrasts.items():\n",
    "\n",
    "    # Relevel design matrix and recalculate logFCs.\n",
    "\n",
    "    relevel_design(dds, [v[0], v[2]])\n",
    "    relevel_design(dds_gene, [v[0], v[2]])\n",
    "\n",
    "    stat_res = DeseqStats(dds, contrast=v, n_cpus=NUM_CPUS)\n",
    "    stat_res_gene = DeseqStats(dds_gene, contrast=v, n_cpus=NUM_CPUS)\n",
    "\n",
    "    stat_res.summary()\n",
    "    stat_res_gene.summary()\n",
    "\n",
    "    stat_res.lfc_shrink()\n",
    "    stat_res_gene.lfc_shrink()\n",
    "\n",
    "    dds.varm[f'LFC_reflevel_{v[2]}'] = dds.varm['LFC'].copy()\n",
    "    dds_gene.varm[f'LFC_reflevel_{v[2]}'] = dds_gene.varm['LFC'].copy()\n",
    "    \n",
    "    dds.uns['stat_results'][k] = stat_res.results_df.copy()\n",
    "    dds_gene.uns['stat_results'][k] = stat_res_gene.results_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.18 Run LRT on full design against null design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run an anova-like test by manually specifying design factors to drop from the full model.\n",
    "\n",
    "lrt_df = likelihood_ratio_test(dds, dds.design_factors)\n",
    "lrt_df_gene = likelihood_ratio_test(dds, dds.design_factors)\n",
    "\n",
    "dds.uns['stat_results_lrtnull'] = lrt_df.copy()\n",
    "dds_gene.uns['stat_results_lrtnull'] = lrt_df_gene.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.19 Clean up DE results and dump."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate -log10_padj and fill NaN. NaN caused by independent filtering of pvalues before bh correction.\n",
    "\n",
    "for i, k in enumerate(contrasts.keys()):\n",
    "    \n",
    "    dds.uns['stat_results'][k]['-log10_padj'] = -1. * np.log10(dds.uns['stat_results'][k]['padj'])\n",
    "    dds_gene.uns['stat_results'][k]['-log10_padj'] = -1. * np.log10(dds_gene.uns['stat_results'][k]['padj'])\n",
    "\n",
    "    dds.uns['stat_results'][k]['-log10_padj'].fillna(0.0, inplace=True)\n",
    "    dds_gene.uns['stat_results'][k]['-log10_padj'].fillna(0.0, inplace=True)\n",
    "\n",
    "    dds.uns['stat_results'][k]['-log10_padj'].replace(np.inf, MAX_NLOG10_PADJ, inplace=True)\n",
    "    dds_gene.uns['stat_results'][k]['-log10_padj'].replace(np.inf, MAX_NLOG10_PADJ, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write dds objects to files for DE and LogFC calculations.\n",
    "\n",
    "# Pydeseq2 supports trend_coeffs/replaced as either np.array or pd.series, np.array required for \n",
    "# saving h5-formatted AnnData objects.\n",
    "dds.uns['trend_coeffs'] = np.array(dds.uns['trend_coeffs'])\n",
    "dds_gene.uns['trend_coeffs'] = np.array(dds_gene.uns['trend_coeffs'])\n",
    "\n",
    "dds.varm['replaced'] = np.array(dds.varm['replaced'])\n",
    "dds_gene.varm['replaced'] = np.array(dds_gene.varm['replaced'])\n",
    "\n",
    "# Add contrasts to uns.\n",
    "dds.uns['contrasts'] = contrasts\n",
    "dds_gene.uns['contrasts'] = contrasts\n",
    "\n",
    "# DeseqDataSet doesn't have native support for writing h5, save as AnnData objects and restore from AnnData objects.\n",
    "\n",
    "dds.write(DDS_TRANSCRIPT_FH)\n",
    "dds_gene.write(DDS_GENE_FH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydeseq2",
   "language": "python",
   "name": "pydeseq2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
