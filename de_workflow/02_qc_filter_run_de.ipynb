{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QC Data, filter samples, and run differential expression testing\n",
    "* User input needed:\n",
    "    * Define specific samples or groups to drop.\n",
    "    * Defining contrasts -> notebook will not complete if contrasts are not defined or if contrasts don't exist in the metadata csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "from IPython.display import HTML\n",
    "import html\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from typing import List\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from scipy.stats import chi2\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "import warnings\n",
    "\n",
    "from pydeseq2.ds import DeseqStats\n",
    "from pydeseq2.dds import DeseqDataSet\n",
    "from pydeseq2.utils import build_design_matrix, nb_nll\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CPUS = 8\n",
    "\n",
    "DATA_PATH = '/data/expression_atlas/runs/%s/' % os.getcwd().split('/')[-1]\n",
    "\n",
    "MULTIQC_PATH = os.path.join(DATA_PATH, 'rnaseq_output/multiqc/star_salmon/multiqc_report.html')\n",
    "\n",
    "COUNT_PATH = os.path.join(DATA_PATH, 'rnaseq_output/star_salmon')\n",
    "\n",
    "RESULTS_PATH = DATA_PATH + 'de_results/%s' % DATA_PATH.rstrip('/').split('/')[-1]\n",
    "\n",
    "METADATA_FH = DATA_PATH + DATA_PATH.rstrip('/').split('/')[-1] + '_metadata.csv'\n",
    "\n",
    "PCA_VARIABLES = ['lib_sizes', 'library_layout', 'instrument_model']\n",
    "\n",
    "DDS_TRANSCRIPT_FH = RESULTS_PATH + '_dds_transcript.h5_ad'\n",
    "DDS_GENE_FH = RESULTS_PATH + '_dds_gene.h5_ad'\n",
    "\n",
    "MAX_NLOG10_PADJ = 400.\n",
    "TRANSCRIPT_SUM_FILTER = 1\n",
    "GENE_SUM_FILTER = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilitiy functions for working with pydeseq2 glms.\n",
    "\n",
    "def relevel_design(dds: DeseqDataSet, ref_level: List[str]) -> None:\n",
    "    \"\"\"Relevels pydeseq2 DeseqDataSet to level in ref_level. Rearranges coefficients to accomodate\n",
    "    new reference level and rebuilds design matrix.\n",
    "\n",
    "    Args:\n",
    "        dds (DeseqDataset) pydeseq2 object to modify\n",
    "        ref_level (List[str]) list of two elements ['condition','new_reference_level']\n",
    "    \"\"\"\n",
    "    if ref_level[0] not in dds.obs.columns:\n",
    "        raise ValueError('%s condition not in design.' % ref_level[0])\n",
    "    if ref_level[1] not in dds.obs[ref_level[0]].values:\n",
    "        raise ValueError('%s condition level not in %s.' % (ref_level[1], ref_level[0]))\n",
    "    if not dds.ref_level:\n",
    "        raise AttributeError('%s define reference level \"ref_level\" for original design.')\n",
    "    \n",
    "    if any(\n",
    "        True if c.startswith(ref_level[0]) and c.endswith(ref_level[1]) else False\n",
    "            for c in dds.obsm['design_matrix'].columns):\n",
    "        print('%s already reference level for %s' % (ref_level[0], ref_level[1]))\n",
    "        return\n",
    "\n",
    "    design_matrix = build_design_matrix(\n",
    "                                    metadata=dds.obs.copy(),\n",
    "                                    design_factors=dds.design_factors,\n",
    "                                    ref_level=ref_level,\n",
    "                                )\n",
    "    \n",
    "    if 'LFC' not in dds.varm.keys():\n",
    "        dds.deseq2()\n",
    "\n",
    "    coef_df = dds.varm['LFC'].copy()\n",
    "\n",
    "    refo = [c.split('_')[-1] for c in dds.varm['LFC'] if c.startswith(ref_level[0])][0]\n",
    "    \n",
    "    columns_to_relevel = [c for c in design_matrix.columns if c.startswith(ref_level[0])]\n",
    "\n",
    "    coef_df['intercept'] = dds.varm['LFC']['intercept'] + \\\n",
    "                                dds.varm['LFC']['%s_%s_vs_%s' % (ref_level[0],ref_level[1],refo)]\n",
    "\n",
    "    for c in columns_to_relevel:\n",
    "        ref, con = c.split(ref_level[0]+'_')[-1].split('_vs_')\n",
    "        \n",
    "        if '%s_%s_vs_%s' % (ref_level[0],con,ref) in dds.varm['LFC'].columns:\n",
    "            coef_df[c] = -1. * dds.varm['LFC']['%s_%s_vs_%s' % (ref_level[0],con,ref)]\n",
    "        else:\n",
    "            coef_df[c] = dds.varm['LFC']['%s_%s_vs_%s' % (ref_level[0],ref,refo)] - \\\n",
    "                                        dds.varm['LFC']['%s_%s_vs_%s' % (ref_level[0],con,refo)] \n",
    "    \n",
    "    columns_drop = [c for c in dds.varm['LFC'] if c.startswith(ref_level[0])]\n",
    "\n",
    "    coef_df.drop(columns_drop, axis=1, inplace=True)\n",
    "    coef_df = coef_df[design_matrix.columns]\n",
    "\n",
    "    dds.varm['LFC'] = coef_df.copy()\n",
    "    dds.obsm['design_matrix'] = design_matrix.copy()\n",
    "    dds.ref_level = ref_level\n",
    "\n",
    "    print('dds releveled to %s-%s' % (ref_level[0], ref_level[1]))\n",
    "\n",
    "\n",
    "\n",
    "def likelihood_ratio_test(dds: DeseqDataSet, factors: List[str], alpha: float=0.05 ) -> pd.DataFrame:\n",
    "    \"\"\"Perform likelihood ratio test of full model against null model lacking factors described in arguments.\n",
    "\n",
    "    Args:\n",
    "        dds (DeseqDataSet) pydeseq2 object with full design\n",
    "        factors (List[str]) factors to drop from full design\n",
    "        alpha (float) alpha value for pvalue adjustment via bh-correction\n",
    "\n",
    "    Returns:\n",
    "        (pd.DataFrame) dataframe containg lr-statistic, pvalue, and padj of full model vs. null model\n",
    "    \"\"\"\n",
    "\n",
    "    if any(True if c not in dds.design_factors else False for c in factors):\n",
    "        raise ValueError('check to make sure all factors %s in design factors.' % (','.join(factors)))\n",
    "\n",
    "    # Calculate likelihood of fit model.    \n",
    "    mu_fit = np.stack(\n",
    "                dds.varm['LFC'].apply(\n",
    "                       lambda x: dds.obsm['size_factors'] * np.exp(dds.obsm['design_matrix'].values @ x), \n",
    "                       axis=1,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    with parallel_backend(\"loky\", inner_max_num_threads=1):\n",
    "                res = Parallel(\n",
    "                    n_jobs=dds.n_processes,\n",
    "                    verbose=dds.joblib_verbosity,\n",
    "                    batch_size=dds.batch_size,\n",
    "                )(\n",
    "                    delayed(nb_nll)(\n",
    "                        dds.X[:, i],\n",
    "                        mu_fit[i,:],\n",
    "                        dds.varm['dispersions'][i],\n",
    "                    )\n",
    "                    for i in range(dds.X.shape[1])\n",
    "                )\n",
    "\n",
    "    l_fit = 2. * np.array(res)\n",
    "\n",
    "    # Calculate likelihood of null model.\n",
    "    dds_null = copy.deepcopy(dds)\n",
    "    \n",
    "    dds_null.obsm['design_matrix'].drop(\n",
    "                        [c for c in dds_null.obsm['design_matrix'] if \\\n",
    "                                    any(c.startswith(f) for f in factors)],\n",
    "                        axis=1,\n",
    "                        inplace=True,\n",
    "                    )\n",
    "    \n",
    "    # Fit null model given estimated dispersion parameters from full model.\n",
    "    dds_null.fit_LFC()\n",
    "\n",
    "    mu_null = np.stack(\n",
    "                dds_null.varm['LFC'].apply(\n",
    "                   lambda x: dds_null.obsm['size_factors'] * \\\n",
    "                            np.exp(dds_null.obsm['design_matrix'].values @ x), \n",
    "                   axis=1,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    with parallel_backend(\"loky\", inner_max_num_threads=1):\n",
    "                res = Parallel(\n",
    "                    n_jobs=dds.n_processes,\n",
    "                    verbose=dds.joblib_verbosity,\n",
    "                    batch_size=dds.batch_size,\n",
    "                )(\n",
    "                    delayed(nb_nll)(\n",
    "                        dds_null.X[:, i],\n",
    "                        mu_null[i,:],\n",
    "                        dds_null.varm['dispersions'][i],\n",
    "                    )\n",
    "                    for i in range(dds_null.X.shape[1])\n",
    "                )\n",
    "\n",
    "    l_null = 2. * np.array(res)\n",
    "\n",
    "    # Perform LRT.\n",
    "    lr_statistic = l_null - l_fit\n",
    "\n",
    "    df = dds.obsm['design_matrix'].shape[1] - dds_null.obsm['design_matrix'].shape[1]\n",
    "\n",
    "    p = chi2.sf(lr_statistic, df)\n",
    "\n",
    "    padj = multipletests(p, alpha=alpha, method=\"fdr_bh\")[1]\n",
    "\n",
    "    return pd.DataFrame(\n",
    "                    np.array([lr_statistic, p, padj]).T, \n",
    "                    index=dds.varm['LFC'].index, \n",
    "                    columns=['lrstat', 'pvalue', 'padj'],\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QC1.1 MultiQC output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the MulitQC report into notebook. Note srcdoc was reqiured to get the html rendered without screwing up the \n",
    "# styling of the notebook while using an iframe. Buttons on the side don't work, but everything else seems to work fine.\n",
    "\n",
    "with open(MULTIQC_PATH,'r') as f_in:\n",
    "    html_raw = html.escape(f_in.read())\n",
    "\n",
    "HTML('<iframe srcdoc=\"%s\" width=\"1200px\" height=\"1000px\"></iframe>' % html_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QC1.2 Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read sample metadata into dataframe\n",
    "\n",
    "metadata = pd.read_csv(METADATA_FH, index_col=0)\n",
    "smallest_condition_size = metadata[[c for c in metadata.columns if c.startswith('condition')]].value_counts()[-1]\n",
    "\n",
    "metadata, smallest_condition_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QC1.3 Define contrasts\n",
    "* Contrasts need to be defined in a dict as contrast_name: [column_name, treatment_level, reference_level].\n",
    "* Each contrast in contrasts will get a DE dataframe defined under anndata.uns['stat_results][<contrast_name>]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually define contrasts given conditions in metadata dataframe. Define reference level for comparisons.\n",
    "\n",
    "\n",
    "# Pydeseq2 contrasts require condition-name, treatment level, reference level format.\n",
    "\n",
    "# Example contrast:\n",
    "# contrasts = {\n",
    "#     'TYPE_2_DIABETES_vs_CONTROL': ['condition-1','DISEASE-1', 'CONTROL'],\n",
    "#     }\n",
    "\n",
    "reference_level = ['condition-1', 'CONTROL']\n",
    "\n",
    "# All underscores are replaced by hyphens.\n",
    "assert (\n",
    "        len(contrasts) > 0 and \n",
    "        all(c[0] in metadata.columns for c in contrasts.values()) and \n",
    "        all(\n",
    "            (   l_1.replace('-','_') in metadata[c].values and \n",
    "                l_2.replace('-','_') in metadata[c].values) \n",
    "                    for c, l_1, l_2 in contrasts.values()\n",
    "        )\n",
    "    )\n",
    "reference_level = [r.replace('_','-') for r in reference_level]\n",
    "contrasts = {\n",
    "    n: [r.replace('_','-') for r in l] for n, l in contrasts.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge effective lengths and average across all runs for transcript and gene dataframes.\n",
    "\n",
    "# Build the transcript length dataframe off of the first sample in the metadata dataframe.\n",
    "transcript_length = pd.read_csv(os.path.join(COUNT_PATH, metadata.index[0], 'quant.sf'), delimiter= '\\t', index_col=0)\n",
    "transcript_length.rename({'EffectiveLength':'EffectiveLength_%s' % metadata.index[0]}, axis=1, inplace=True)\n",
    "transcript_length.drop(['Length', 'TPM', 'NumReads'], inplace=True, axis=1)\n",
    "\n",
    "gene_length = pd.read_csv(os.path.join(COUNT_PATH, metadata.index[0], 'quant.genes.sf'), delimiter= '\\t', index_col=0)\n",
    "gene_length.rename({'EffectiveLength':'EffectiveLength_%s' % metadata.index[0]}, axis=1, inplace=True)\n",
    "gene_length.drop(['Length', 'TPM', 'NumReads'], inplace=True, axis=1)\n",
    "\n",
    "# Populate samples into effective length dataframe with remaining samples.\n",
    "for srx in tqdm(metadata.index[1:]):\n",
    "    df = pd.read_csv(os.path.join(COUNT_PATH, srx, 'quant.sf'), delimiter='\\t', index_col=0)\n",
    "    df.drop(['Length', 'TPM', 'NumReads'], inplace=True, axis=1)\n",
    "    df.rename({'EffectiveLength':'EffectiveLength_%s' % srx}, axis=1, inplace=True)\n",
    "    transcript_length = transcript_length.merge(df, on='Name')\n",
    "\n",
    "    df_gene = pd.read_csv(os.path.join(COUNT_PATH, srx, 'quant.genes.sf'), delimiter='\\t', index_col=0)\n",
    "    df_gene.drop(['Length', 'TPM', 'NumReads'], inplace=True, axis=1)\n",
    "    df_gene.rename({'EffectiveLength':'EffectiveLength_%s' % srx}, axis=1, inplace=True)\n",
    "    gene_length = gene_length.merge(df_gene, on='Name')\n",
    "\n",
    "\n",
    "# Average effective lengths. It would probably be better to use a weighted averaging similar to tximport.\n",
    "transcript_length['length'] = transcript_length.mean(axis=1)\n",
    "gene_length['length'] = gene_length.mean(axis=1)\n",
    "transcript_length.drop([c for c in transcript_length.columns if c.startswith('EffectiveLength_')], inplace=True, axis=1)\n",
    "gene_length.drop([c for c in gene_length.columns if c.startswith('EffectiveLength_')], inplace=True, axis=1)\n",
    "\n",
    "transcript_length.shape, gene_length.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in transcript and gene count/TPM dataframes.\n",
    "\n",
    "expression = pd.read_csv(os.path.join(COUNT_PATH, 'salmon.merged.transcript_counts.tsv'), delimiter = '\\t', index_col=0)\n",
    "gene_transcript_mapping = expression[['gene_id']].copy().reset_index()\n",
    "expression.drop('gene_id', inplace=True, axis=1)\n",
    "\n",
    "tpm = pd.read_csv(os.path.join(COUNT_PATH, 'salmon.merged.transcript_tpm.tsv'), delimiter = '\\t', index_col=0)\n",
    "tpm.drop('gene_id', inplace=True, axis=1)\n",
    "\n",
    "# See: https://nf-co.re/rnaseq/3.12.0/docs/output#salmon on output choice below \n",
    "# salmon.merged.gene_counts_length_scaled.tsv is the gene-level output of nf-core rnaseq that is bias-corrected\n",
    "# and is already scaled by potential transcript length\n",
    "expression_gene = pd.read_csv(os.path.join(COUNT_PATH, 'salmon.merged.gene_counts_length_scaled.tsv'), delimiter='\\t', index_col=0)\n",
    "expression_gene.drop('gene_name', inplace=True, axis=1)\n",
    "\n",
    "tpm_gene = pd.read_csv(os.path.join(COUNT_PATH, 'salmon.merged.gene_tpm.tsv'), delimiter='\\t', index_col=0)\n",
    "tpm_gene.drop('gene_name', inplace=True, axis=1)\n",
    "\n",
    "expression.shape, expression_gene.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter expression dataframes on samples not in metadata.csv\n",
    "\n",
    "samples_to_drop = [c for c in expression.columns if c not in metadata.index]\n",
    "\n",
    "expression.drop(samples_to_drop, axis=1, inplace=True)\n",
    "expression_gene.drop(samples_to_drop, axis=1, inplace=True)\n",
    "tpm.drop(samples_to_drop, axis=1, inplace=True)\n",
    "tpm_gene.drop(samples_to_drop, axis=1, inplace=True)\n",
    "expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QC1.4 Drop samples or groups from count dataframe or design matrix, respectively.\n",
    "* Samples are dropped based on \"SRX\" id, or cell in 'accession' column of the metadata dataframe.\n",
    "* Groups are dropped based on group id ex. 'group-1', a grouping present in the metadata dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop specific samples from dataframe. Provide accession name of samples to remove from analysis.\n",
    "\n",
    "# Clear outlier.\n",
    "samples_to_drop = []\n",
    "\n",
    "expression.drop(samples_to_drop, axis=1, inplace=True)\n",
    "expression_gene.drop(samples_to_drop, axis=1, inplace=True)\n",
    "tpm.drop(samples_to_drop, axis=1, inplace=True)\n",
    "tpm_gene.drop(samples_to_drop, axis=1, inplace=True)\n",
    "metadata.drop(samples_to_drop, axis=0, inplace=True)\n",
    "expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop specific conditions/groups from metadata dataframe. \n",
    "\n",
    "groups_to_drop = []\n",
    "metadata.drop(groups_to_drop, axis=1, inplace=True)\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter expression dataframe and prepare for QC/EDA.\n",
    "\n",
    "filtered_expression_transcript = expression.T.copy()\n",
    "filtered_expression_transcript = filtered_expression_transcript.loc[:,\n",
    "                                        filtered_expression_transcript.sum(axis=0) >= TRANSCRIPT_SUM_FILTER\n",
    "                                    ]\n",
    "\n",
    "# Tag to take another look, filter later \n",
    "filtered_expression_transcript = filtered_expression_transcript.loc[:,\n",
    "                                        (filtered_expression_transcript >= TRANSCRIPT_SUM_FILTER).sum(axis=0) >\n",
    "                                            smallest_condition_size\n",
    "                                    ]\n",
    "\n",
    "filtered_tpm_transcript = tpm.T.copy()\n",
    "filtered_tpm_transcript = filtered_tpm_transcript[filtered_expression_transcript.columns]\n",
    "\n",
    "filtered_expression_gene = expression_gene.T.copy()\n",
    "filtered_expression_gene = filtered_expression_gene.loc[:,\n",
    "                                        filtered_expression_gene.sum(axis=0) >= GENE_SUM_FILTER\n",
    "                                    ]\n",
    "\n",
    "# Tag to take another look, filter later \n",
    "filtered_expression_gene = filtered_expression_gene.loc[:,\n",
    "                                        (filtered_expression_gene >= GENE_SUM_FILTER).sum(axis=0) > \n",
    "                                            smallest_condition_size\n",
    "                                    ]\n",
    "\n",
    "filtered_tpm_gene = tpm_gene.T.copy()\n",
    "filtered_tpm_gene = filtered_tpm_gene[filtered_expression_gene.columns]\n",
    "\n",
    "assert (\n",
    "        all([i == j for i,j in zip(filtered_expression_gene.columns, filtered_tpm_gene.columns)]) and \n",
    "        all([i == j for i,j in zip(filtered_expression_transcript.columns, filtered_tpm_transcript.columns)]) and \n",
    "        all([i == j for i,j in zip(filtered_expression_gene.index, filtered_tpm_gene.index)]) and\n",
    "        all([i == j for i,j in zip(filtered_expression_transcript.index, filtered_tpm_transcript.index)])\n",
    "    )\n",
    "\n",
    "(   expression.shape, \n",
    "    filtered_expression_transcript.shape, \n",
    "    expression_gene.shape, \n",
    "    filtered_expression_gene.shape, \n",
    "    filtered_tpm_transcript.shape, \n",
    "    filtered_tpm_gene.shape, \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Deseq dataframe (AnnData object).\n",
    "\n",
    "# DeseqDataSet expects integers in counts matrix, need to check in on the default method for \n",
    "# rounding fractional counts to integers in tximport.\n",
    " \n",
    "dds = DeseqDataSet(\n",
    "    counts = filtered_expression_transcript.astype(int), \n",
    "    metadata = metadata, \n",
    "    design_factors = \n",
    "        [c for c in metadata.columns if c.startswith('group')]+\n",
    "        [c for c in metadata.columns if c.startswith('condition')],\n",
    "    ref_level=reference_level,\n",
    "    refit_cooks = True, \n",
    "    n_cpus = NUM_CPUS, \n",
    "    )\n",
    "\n",
    "dds_gene = DeseqDataSet(\n",
    "    counts = filtered_expression_gene.astype(int), \n",
    "    metadata = metadata, \n",
    "    design_factors = \n",
    "        [c for c in metadata.columns if c.startswith('group')]+\n",
    "        [c for c in metadata.columns if c.startswith('condition')],\n",
    "    ref_level=reference_level,\n",
    "    refit_cooks = True, \n",
    "    n_cpus = NUM_CPUS, \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set gene-transcript mapping attribute in uns for comparisons between \n",
    "# gene- and transcript-level quantifications.\n",
    "\n",
    "dds.uns['gene_transcript_mapping'] = gene_transcript_mapping\n",
    "dds_gene.uns['gene_transcript_mapping'] = gene_transcript_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set raw TPMs as layer in dds objects.\n",
    "\n",
    "dds.layers['raw_tpm'] = np.array(filtered_tpm_transcript)\n",
    "dds_gene.layers['raw_tpm'] = np.array(filtered_tpm_gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the average effective lengths into the var dataframe.\n",
    "\n",
    "dds.var = dds.var.merge(transcript_length, left_index=True, right_index=True)\n",
    "dds_gene.var = dds_gene.var.merge(gene_length, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QC1.5 computed size-factors and library sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute size-factors and library sizes.\n",
    "\n",
    "dds.fit_size_factors()\n",
    "dds.obs['size_factors'] = dds.obsm['size_factors']\n",
    "dds.obs['lib_sizes'] = dds.X.sum(axis=1)\n",
    "\n",
    "dds_gene.fit_size_factors()\n",
    "dds_gene.obs['size_factors'] = dds_gene.obsm['size_factors']\n",
    "dds_gene.obs['lib_sizes'] = dds_gene.X.sum(axis=1)\n",
    "\n",
    "dds.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance-stabilizing transformation.\n",
    "\n",
    "dds.vst()\n",
    "dds_gene.vst()\n",
    "\n",
    "dds.layers['vst_counts'], dds_gene.layers['vst_counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set recoverable count data.\n",
    "\n",
    "dds.layers['counts'] = dds.X.copy()\n",
    "dds_gene.layers['counts'] = dds_gene.X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute fractional counts to get a quick idea for any weird skews in library composition.\n",
    "\n",
    "dds.layers['fraction_counts'] = dds.layers['counts'] / np.reshape(dds.layers['counts'].sum(axis=1), (-1,1))\n",
    "dds_gene.layers['fraction_counts'] = dds_gene.layers['counts'] / np.reshape(dds_gene.layers['counts'].sum(axis=1), (-1,1))\n",
    "\n",
    "dds.layers['fraction_counts'], dds_gene.layers['fraction_counts']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QC1.6 CDF curves library composition by fraction counts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CDF of fractional composition of libraries. \n",
    "\n",
    "ax_transcript = sns.ecdfplot(np.log2(dds.layers['fraction_counts'].T))\n",
    "ax_transcript.set_xlabel('log2 fraction counts')\n",
    "ax_transcript.legend(\n",
    "        labels=dds.obs.index, \n",
    "        loc='upper left', \n",
    "        bbox_to_anchor=(1.,1.), \n",
    "        ncols=1 if len(dds.obs.index) < 10 else int(len(dds.obs.index)/10),\n",
    "        frameon=False,\n",
    "    )\n",
    "ax_transcript.set_title('transcript')\n",
    "plt.show()\n",
    "\n",
    "ax_gene = sns.ecdfplot(np.log2(dds_gene.layers['fraction_counts'].T))\n",
    "ax_gene.set_xlabel('log2 fraction counts')\n",
    "ax_gene.legend(\n",
    "        labels=dds_gene.obs.index, \n",
    "        loc='upper left', \n",
    "        bbox_to_anchor=(1.,1.), \n",
    "        ncols=1 if len(dds_gene.obs.index) < 10 else int(len(dds_gene.obs.index)/10),\n",
    "        frameon=False,\n",
    "    )\n",
    "ax_gene.set_title('gene')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace count matrix with variance-transformed counts, following DESeq2 recommendation\n",
    "# for preprocessing count data before QC visualization.\n",
    "\n",
    "dds.X = dds.layers['vst_counts'].copy()\n",
    "dds_gene.X = dds_gene.layers['vst_counts'].copy()\n",
    "\n",
    "np.nan_to_num(dds.X, copy=False)\n",
    "np.nan_to_num(dds_gene.X, copy=False)\n",
    "\n",
    "dds.layers['counts'], dds.X, dds.layers['vst_counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale transformed variables.\n",
    "\n",
    "sc.pp.scale(dds)\n",
    "sc.pp.scale(dds_gene)\n",
    "\n",
    "np.nan_to_num(dds.X, copy=False)\n",
    "np.nan_to_num(dds_gene.X, copy=False)\n",
    "\n",
    "dds.X.mean(axis=0), dds.X.std(axis=0), dds_gene.X.mean(axis=0), dds_gene.X.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QC1.7 PCA on vst-counts colored on conditions, groups, and defined PCA variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminary PCA on transcript- and gene-level data.\n",
    "\n",
    "suffix_size = 4\n",
    "\n",
    "sc.pp.pca(dds)\n",
    "ax_transcript_pca = sc.pl.pca( \n",
    "    dds, \n",
    "    color=\n",
    "        [c for c in dds.obs.columns if c.startswith('group')]+\n",
    "        [c for c in dds.obs.columns if c.startswith('condition')]+\n",
    "        ['lib_sizes', 'library_layout', 'instrument_model'], \n",
    "    size = 128,\n",
    "    show=False,\n",
    "    )\n",
    "\n",
    "for i, s in enumerate(dds.obsm['X_pca']):\n",
    "    if type(ax_transcript_pca) == list:\n",
    "        for ax in ax_transcript_pca:\n",
    "            ax.text(s[0], s[1], dds.obs.index[i][-suffix_size:])\n",
    "    else:\n",
    "        ax_transcript_pca.text(s[0], s[1], dds.obs.index[i][-suffix_size:])\n",
    "\n",
    "sc.pp.pca(dds_gene)\n",
    "ax_gene_pca = sc.pl.pca(\n",
    "    dds_gene, \n",
    "    color=\n",
    "        [c for c in dds_gene.obs.columns if c.startswith('group')]+\n",
    "        [c for c in dds_gene.obs.columns if c.startswith('condition')]+\n",
    "        ['lib_sizes', 'library_layout', 'instrument_model'], \n",
    "    size = 128,\n",
    "    show=False, \n",
    "    )\n",
    "\n",
    "for i, s in enumerate(dds_gene.obsm['X_pca']):\n",
    "    if type(ax_gene_pca) == list:\n",
    "        for ax in ax_gene_pca:\n",
    "            ax.text(s[0], s[1], dds_gene.obs.index[i][-suffix_size:])\n",
    "    else:\n",
    "        ax_gene_pca.text(s[0], s[1], dds_gene.obs.index[i][-suffix_size:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PCA out to 4 PCs.\n",
    "\n",
    "transcript_color_columns = [c for c in dds.obs.columns if c.startswith(('group', 'condition',))]+ \\\n",
    "    ['lib_sizes', 'library_layout', 'instrument_model']\n",
    "ax_transcript_pca = sc.pl.pca( \n",
    "    dds, \n",
    "    color=transcript_color_columns, \n",
    "    size = 128,\n",
    "    show=False,\n",
    "    ncols=len(transcript_color_columns),\n",
    "    components=['1,2', '2,3', '3,4', '4,5'],\n",
    ")\n",
    "\n",
    "gene_color_columns = [c for c in dds_gene.obs.columns if c.startswith(('group', 'condition',))]+ \\\n",
    "    ['lib_sizes', 'library_layout', 'instrument_model']\n",
    "ax_transcript_pca = sc.pl.pca( \n",
    "    dds_gene, \n",
    "    color=gene_color_columns, \n",
    "    size = 128,\n",
    "    show=False,\n",
    "    ncols=len(gene_color_columns),\n",
    "    components=['1,2', '2,3', '3,4', '4,5'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QC1.8 PC - explained variance ratios. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot explained variance ratios.\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "ax[0].plot(dds.uns['pca']['variance_ratio'])\n",
    "ax[1].plot(dds_gene.uns['pca']['variance_ratio'])\n",
    "\n",
    "ax[0].set_ylabel('fraction explained variance')\n",
    "ax[0].set_xlabel('PC')\n",
    "ax[1].set_xlabel('PC')\n",
    "ax[0].set_title('Transcript')\n",
    "ax[1].set_title('Gene')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QC1.9 PCA loadings for transcript(top) and gene(bottom)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loadings for first 3 PCs.\n",
    "\n",
    "sc.pl.pca_loadings(dds, components = '1,2,3')\n",
    "sc.pl.pca_loadings(dds_gene, components = '1,2,3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QC1.10 sample-sample pearson correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample-sample pearson correlation.\n",
    "\n",
    "dds.layers['vst_counts'].shape\n",
    "dds_gene.layers['vst_counts'].shape\n",
    "\n",
    "dist = np.corrcoef(dds.layers['vst_counts'])\n",
    "\n",
    "ax_transcript = sns.heatmap(\n",
    "                dist, \n",
    "                xticklabels=dds.obs.index, \n",
    "                yticklabels=dds.obs['condition-1'], \n",
    "                cbar_kws={'label': 'pearson r'}, \n",
    "            )\n",
    "ax_transcript.set_title('transcript')\n",
    "plt.show()\n",
    "\n",
    "dist = np.corrcoef(dds_gene.layers['vst_counts'])\n",
    "\n",
    "ax_gene = sns.heatmap(\n",
    "                dist, \n",
    "                xticklabels=dds_gene.obs.index, \n",
    "                yticklabels=dds_gene.obs['condition-1'], \n",
    "                cbar_kws={'label': 'pearson r'},\n",
    "            )\n",
    "ax_gene.set_title('gene')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sample-sample pearson correlation with plotly.\n",
    "\n",
    "# dds.layers['vst_counts'].shape\n",
    "# dds_gene.layers['vst_counts'].shape\n",
    "\n",
    "# dist = np.corrcoef(dds.layers['vst_counts'])\n",
    "\n",
    "# fig = go.Figure(\n",
    "#         data=go.Heatmap(\n",
    "#                     z=dist,\n",
    "#                     x=dds.obs.index,\n",
    "#                     y=dds.obs.reset_index()[\n",
    "#                         [c for c in dds.obs.columns if c.startswith('condition') or c.startswith('group')]+['accession']\n",
    "#                                             ].agg('_'.join,axis=1),\n",
    "#                     hoverongaps = False, \n",
    "#                     colorbar={'title': 'pearson r'},\n",
    "#                 )\n",
    "#             )\n",
    "\n",
    "# fig.update_layout(\n",
    "#                 height=500,\n",
    "#                 width=700,\n",
    "#                 title_text='transcript'\n",
    "#             )\n",
    "\n",
    "# iplot(fig)\n",
    "\n",
    "# dist = np.corrcoef(dds_gene.layers['vst_counts'])\n",
    "\n",
    "# fig = go.Figure(\n",
    "#         data=go.Heatmap(\n",
    "#                     z=dist,\n",
    "#                     x=dds_gene.obs.index,\n",
    "#                     y=dds_gene.obs.reset_index()[\n",
    "#                         [c for c in dds_gene.obs.columns if c.startswith('condition') or c.startswith('group')]+['accession']\n",
    "#                                             ].agg('_'.join, axis=1),\n",
    "#                     hoverongaps = False, \n",
    "#                     colorbar={'title': 'pearson r'},\n",
    "#                 )\n",
    "#             )\n",
    "\n",
    "# fig.update_layout(\n",
    "#                 height=500,\n",
    "#                 width=700,\n",
    "#                 title_text='gene'\n",
    "#             )\n",
    "\n",
    "# iplot(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore the original counts data.\n",
    "\n",
    "dds.X = dds.layers['counts'].copy()\n",
    "dds_gene.X = dds_gene.layers['counts'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit dispersions, logFCs, and calculate cooks.\n",
    "\n",
    "dds.deseq2()\n",
    "dds_gene.deseq2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DE1.1 fitted and squeezed dispersions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot fitted dispersions.\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "ax[0].scatter(\n",
    "        np.log(dds.varm['_normed_means']), \n",
    "        np.log(dds.varm['genewise_dispersions']), \n",
    "        s=1, \n",
    "        alpha=0.01, \n",
    "        label='raw',\n",
    "    )\n",
    "ax[0].scatter(\n",
    "        np.log(dds.varm['_normed_means']), \n",
    "        np.log(dds.varm['dispersions']), \n",
    "        s=1, \n",
    "        alpha=0.01, \n",
    "        label='squeezed',\n",
    "    )\n",
    "ax[0].scatter(\n",
    "        np.log(dds.varm['_normed_means']), \n",
    "        np.log(dds.varm['fitted_dispersions']), \n",
    "        s=1, \n",
    "        alpha=0.01, \n",
    "        label='trended', \n",
    "        c='r', \n",
    "    )\n",
    "ax[0].set_ylabel('log dispersions')\n",
    "ax[0].set_xlabel('log normalized mean')\n",
    "ax[0].set_title('transcript-level')\n",
    "ax[0].legend(frameon=False)\n",
    "legend = ax[0].legend(frameon=False)\n",
    "for lh in legend.legend_handles:\n",
    "    lh.set_alpha(1)\n",
    "\n",
    "ax[1].scatter(\n",
    "        np.log(dds_gene.varm['_normed_means']), \n",
    "        np.log(dds_gene.varm['genewise_dispersions']), \n",
    "        s=1, \n",
    "        alpha=0.01, \n",
    "        label='raw',\n",
    "    )\n",
    "ax[1].scatter(\n",
    "        np.log(dds_gene.varm['_normed_means']), \n",
    "        np.log(dds_gene.varm['dispersions']), \n",
    "        s=1, \n",
    "        alpha=0.01, \n",
    "        label='squeezed',\n",
    "    )\n",
    "ax[1].scatter(\n",
    "        np.log(dds_gene.varm['_normed_means']), \n",
    "        np.log(dds_gene.varm['fitted_dispersions']), \n",
    "        s=1, \n",
    "        alpha=0.01, \n",
    "        label='trended', \n",
    "        c='r', \n",
    "    )\n",
    "ax[1].set_xlabel('log normalized mean')\n",
    "ax[1].set_title('gene-level')\n",
    "legend = ax[1].legend(frameon=False)\n",
    "for lh in legend.legend_handles:\n",
    "    lh.set_alpha(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DE1.2 metadata and design matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dds.obsm['design_matrix'], dds_gene.obsm['design_matrix']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DE1.3 Fit model and run tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Stats object. Define relevant contrasts for DE and LogFC computations and run tests. \n",
    "\n",
    "# Holds all DeseqStats objects as defined in contrasts.\n",
    "dds.uns['stat_results'] = {}\n",
    "dds_gene.uns['stat_results'] = {}\n",
    "\n",
    "for k, v in contrasts.items():\n",
    "\n",
    "    # Relevel design matrix and recalculate logFCs.\n",
    "\n",
    "    relevel_design(dds, [v[0], v[2]])\n",
    "    relevel_design(dds_gene, [v[0], v[2]])\n",
    "\n",
    "    stat_res = DeseqStats(dds, contrast=v, n_cpus=NUM_CPUS)\n",
    "    stat_res_gene = DeseqStats(dds_gene, contrast=v, n_cpus=NUM_CPUS)\n",
    "\n",
    "    stat_res.summary()\n",
    "    stat_res_gene.summary()\n",
    "\n",
    "    stat_res.lfc_shrink()\n",
    "    stat_res_gene.lfc_shrink()\n",
    "\n",
    "    dds.varm['LFC_reflevel_%s' % v[2]] = dds.varm['LFC'].copy()\n",
    "    dds_gene.varm['LFC_reflevel_%s' % v[2]] = dds_gene.varm['LFC'].copy()\n",
    "    \n",
    "    dds.uns['stat_results'][k] = stat_res.results_df.copy()\n",
    "    dds_gene.uns['stat_results'][k] = stat_res_gene.results_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DE1.4 Run LRT on full design against null design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run an anova-like test by manually specifying design factors to drop from the full model.\n",
    "\n",
    "\n",
    "# lrt_df = likelihood_ratio_test(dds, dds.design_factors)\n",
    "# lrt_df_gene = likelihood_ratio_test(dds, dds.design_factors)\n",
    "\n",
    "# display(lrt_df)\n",
    "# display(lrt_df_gene)\n",
    "\n",
    "# dds.uns['stat_results_lrtnull'] = lrt_df.copy()\n",
    "# dds_gene.uns['stat_results_lrtnull'] = lrt_df_gene.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate -log10_padj and fill NaN. NaN caused by independent filtering of pvalues before bh correction.\n",
    "\n",
    "for i, k in enumerate(contrasts.keys()):\n",
    "    \n",
    "    dds.uns['stat_results'][k]['-log10_padj'] = -1. * np.log10(dds.uns['stat_results'][k]['padj'])\n",
    "    dds_gene.uns['stat_results'][k]['-log10_padj'] = -1. * np.log10(dds_gene.uns['stat_results'][k]['padj'])\n",
    "\n",
    "    dds.uns['stat_results'][k]['-log10_padj'].fillna(0.0, inplace=True)\n",
    "    dds_gene.uns['stat_results'][k]['-log10_padj'].fillna(0.0, inplace=True)\n",
    "\n",
    "    dds.uns['stat_results'][k]['-log10_padj'].replace(np.inf, MAX_NLOG10_PADJ, inplace=True)\n",
    "    dds_gene.uns['stat_results'][k]['-log10_padj'].replace(np.inf, MAX_NLOG10_PADJ, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump results dataframes to results folder.\n",
    "\n",
    "for k in contrasts.keys():\n",
    "\n",
    "    dds.uns['stat_results'][k].to_csv('%s_%s_%s.csv' % (RESULTS_PATH, 'transcript', k))\n",
    "    dds_gene.uns['stat_results'][k].to_csv('%s_%s_%s.csv' % (RESULTS_PATH, 'gene', k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write dds objects to files for DE and LogFC calculations.\n",
    "\n",
    "# Pydeseq2 supports trend_coeffs/replaced as either np.array or pd.series, np.array required for \n",
    "# saving h5-formatted AnnData objects.\n",
    "dds.uns['trend_coeffs'] = np.array(dds.uns['trend_coeffs'])\n",
    "dds_gene.uns['trend_coeffs'] = np.array(dds_gene.uns['trend_coeffs'])\n",
    "\n",
    "dds.varm['replaced'] = np.array(dds.varm['replaced'])\n",
    "dds_gene.varm['replaced'] = np.array(dds_gene.varm['replaced'])\n",
    "\n",
    "# Add contrasts to uns.\n",
    "dds.uns['contrasts'] = contrasts\n",
    "dds_gene.uns['contrasts'] = contrasts\n",
    "\n",
    "# DeseqDataSet doesn't have native support for writing h5, save as AnnData objects and restore from\n",
    "# AnnData objects.\n",
    "\n",
    "dds.write(DDS_TRANSCRIPT_FH)\n",
    "dds_gene.write(DDS_GENE_FH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydeseq2",
   "language": "python",
   "name": "pydeseq2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
