{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Sample Sheets and Define Groups/Conditions\n",
    "* User input needed:\n",
    "    * Define functions, condition levels, and group levels in cell below.\n",
    "    * Define specific samples to drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import IPython\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions, condition levels, and group levels in metadata dataframe.\n",
    "* Description of variables that need to be set in below cell:\n",
    "    * SRX_COLUMN -> the SRX accession is usually present in 'experiment_accession' column, but sometimes present in 'run_accession' column depending on project.\n",
    "    * SAMPLE_CONDITION_COLUMNS -> dictionary with key='condition_name' and value='column to search for different condition levels'.\n",
    "    * SAMPLE_GROUP_COLUMNS -> similar to above, dictionary with key='group_name' and value='column to search for different group levels'.\n",
    "    * SAMPLE_CONDITIONS -> dictionary of dictionaries, with outer key='condition_name', inner key='string or pattern to search for in cell', and inner value='condition level to set'.\n",
    "    * SAMPLE_GROUPS -> dictionary of dictionaries, with outer key='group_name', inner key='string or patter to search for in cell', and inner value='group level to set'.\n",
    "* Description of functions that need to be configured in below cell:\n",
    "    * filter_conditon -> described in docstring.\n",
    "    * filter_group -> described in docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA_PATH = os.getcwd()\n",
    "\n",
    "# DATA_PATH = '/data/expression_atlas/v1/GSE122459/'\n",
    "# DATA_PATH = '/data/expression_atlas/v1/GSE110914/'\n",
    "# DATA_PATH = '/data/expression_atlas/v1/GSE162828/'\n",
    "# DATA_PATH = '/data/expression_atlas/v1/GSE120178/'\n",
    "# DATA_PATH = '/data/expression_atlas/v1/GSE102371/'\n",
    "# DATA_PATH = '/data/expression_atlas/v1/GSE112087/'\n",
    "# DATA_PATH = '/data/expression_atlas/v1/GSE139358/'\n",
    "# DATA_PATH = '/data/expression_atlas/v1/GSE112087/'\n",
    "DATA_PATH = '/data/expression_atlas/v1/GSE80183/'\n",
    "\n",
    "RESULTS_PATH = '' + 'de_results/%s' % DATA_PATH.rstrip('/').split('/')[-1]\n",
    "\n",
    "#METADATA_FH = '' + '%s_metadata.csv' % DATA_PATH.rstrip('/').split('/')[-1]\n",
    "METADATA_FH = RESULTS_PATH + '_metadata.csv'\n",
    "\n",
    "# Define functions, condition levels, and group levels in metadata dataframe.\n",
    "SRX_COLUMN = 'experiment_accession'\n",
    "# SRX_COLUMN = 'run_accession\n",
    "\n",
    "SAMPLE_CONDITION_COLUMNS = {\n",
    "    'condition-1': 'sample_description',\n",
    "    }\n",
    "\n",
    "# SAMPLE_CONDITION_COLUMNS = {\n",
    "#     'condition_1': 'sample_description',\n",
    "#     'condition_2': 'sample_description',\n",
    "#     }\n",
    "\n",
    "# SAMPLE_GROUP_COLUMNS = {\n",
    "#     'group_1': 'instrument_model',\n",
    "#     }\n",
    "\n",
    "SAMPLE_GROUP_COLUMNS = {\n",
    "\n",
    "    }\n",
    "\n",
    "# # GSE139358\n",
    "# SAMPLE_CONDITIONS = {\n",
    "#     'condition_1' : {\n",
    "#         'LDG_0':'TREAT_1',\n",
    "#         'NDN_0':'TREAT_1',\n",
    "#         'LDG_SLE':'TREAT_1',\n",
    "#         'NDN_SLE':'TREAT_1', \n",
    "#         'NDN_ctrl':'CONTROL',\n",
    "#         },\n",
    "#     'condition_2' : {\n",
    "#         'NDN':'A',\n",
    "#         'LDG':'B',\n",
    "#         }\n",
    "#     }\n",
    "\n",
    "# # GSE112087\n",
    "# SAMPLE_CONDITIONS = {\n",
    "#     'condition_1' : {\n",
    "#         'MON_SLE':'TREAT_1', \n",
    "#         'MS_NORM':'CONTROL',\n",
    "#         }\n",
    "#     }\n",
    "\n",
    "# # GSE122459\n",
    "# SAMPLE_CONDITIONS = {\n",
    "#     'condition_1' : {\n",
    "#         'SLE':'TREAT_1', \n",
    "#         'healthy':'CONTROL',\n",
    "#         }\n",
    "#     }\n",
    "\n",
    "# # GSE110914\n",
    "# SAMPLE_CONDITIONS = {\n",
    "#     'condition_1' : {\n",
    "#         'T1D':'TREAT_2',\n",
    "#         'preT1D':'TREAT_1', \n",
    "#         'HC':'CONTROL',\n",
    "#         }\n",
    "#     }\n",
    "\n",
    "# GSE80183\n",
    "SAMPLE_CONDITIONS = {\n",
    "    'condition-1' : {\n",
    "        'SLE':'DISEASE',\n",
    "        'Control':'CONTROL',\n",
    "        },\n",
    "    }\n",
    "\n",
    "# # GSE162828\n",
    "# SAMPLE_CONDITIONS = {\n",
    "#     'condition_1': {\n",
    "#         'SLE':'TREAT_1',\n",
    "#         'Healthy':'CONTROL',\n",
    "#         }\n",
    "#     }\n",
    "\n",
    "# # GSE120178\n",
    "# SAMPLE_CONDITIONS = {\n",
    "#     'condition_1' : {\n",
    "#         'A':'TREAT_1',\n",
    "#         'E':'TREAT_1',\n",
    "#         'L':'TREAT_1',\n",
    "#         'B':'CONTROL',  \n",
    "#         }\n",
    "#     }\n",
    "\n",
    "# # GSE102371\n",
    "# SAMPLE_CONDITIONS = {\n",
    "#   'condition_1' : {\n",
    "#     'islet preparation from normo':'CONTROL',\n",
    "#     'islet preparation from long':'TREAT_1',\n",
    "#     'islet preparation from short':'TREAT_1',\n",
    "#         }\n",
    "#     }\n",
    "\n",
    "# # GSE122459\n",
    "# SAMPLE_GROUPS = {\n",
    "#     'group_1': {\n",
    "#         'Illumina HiSeq 2500':'A',\n",
    "#         'NextSeq 500':'B',\n",
    "#         },\n",
    "#     }\n",
    "\n",
    "SAMPLE_GROUPS = {\n",
    "\n",
    "    }\n",
    "\n",
    "# List of columns to keep in metadata file.\n",
    "KEEP_COLUMNS = [ \n",
    "            'single_end', \n",
    "            'strandedness', \n",
    "            'experiment_accession', \n",
    "            'submission_accession', \n",
    "            'library_layout', \n",
    "            'library_selection', \n",
    "            'library_source', \n",
    "            'library_strategy', \n",
    "            'library_name', \n",
    "            'instrument_model', \n",
    "            'instrument_platform', \n",
    "            'read_count', \n",
    "            'tax_id', \n",
    "            'sample_title', \n",
    "            'experiment_title', \n",
    "            'sample_description',\n",
    "        ]\n",
    "\n",
    "def filter_condition(cell: str, condition_key: str) -> bool:\n",
    "    '''Modify to check for a key present in SAMPLE_CONDITION\n",
    "\n",
    "    Args:\n",
    "        cell (str) contents of single cell from metadata dataframe\n",
    "        condition_key (str) key to search cell \n",
    "\n",
    "    Returns:\n",
    "        (bool) transfer key to cell\n",
    "    '''\n",
    "    # return cell.startswith(condition_key)\n",
    "    return condition_key in cell\n",
    "    # return cell.endswith(condition_key)\n",
    "\n",
    "def filter_group(cell: str, group_key: str) -> bool:\n",
    "    '''Modify to check for key present in SAMPLE_GROUP\n",
    "\n",
    "    Args:\n",
    "        cell (str) contents of single cell from metadata dataframe\n",
    "        group_key (str) key to search cell\n",
    "\n",
    "    Returns:\n",
    "        (bool) transfer key to cell\n",
    "    '''\n",
    "    #return cell.startswith(group_key)\n",
    "    return group_key in cell\n",
    "    # return cell.endswith(group_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read output of nf-core RNA-seq samplesheet into dataframe\n",
    "\n",
    "samplesheet_valid = pd.read_csv(os.path.join(DATA_PATH, 'rnaseq_output/pipeline_info/samplesheet.valid.csv'))\n",
    "samplesheet_valid\n",
    "# print(samplesheet_valid['sample_description'].to_list())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop samples from metadata.\n",
    "* Samples are dropped based on \"SRX\" id in metadata dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out samples that aren't desired in further analysis.\n",
    "\n",
    "samples_to_remove = []\n",
    "\n",
    "sample_indices = samplesheet_valid[samplesheet_valid[SRX_COLUMN].isin(samples_to_remove)].index\n",
    "\n",
    "sample_indices\n",
    "samplesheet_valid.drop(sample_indices, axis=0, inplace=True)\n",
    "\n",
    "samplesheet_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match sample conditions and groups to those in SAMPLE_CONDITION_PREFIXES and SAMPLE_GROUP_PREFIXES \n",
    "\n",
    "for k, v in SAMPLE_CONDITION_COLUMNS.items():\n",
    "    samplesheet_valid[k] = np.nan\n",
    "    for kg, vg in SAMPLE_CONDITIONS[k].items():\n",
    "        samplesheet_valid.loc[samplesheet_valid[v].map(lambda x: filter_condition(x, kg)), k] = vg\n",
    "    assert not samplesheet_valid[k].isnull().any()\n",
    "\n",
    "\n",
    "for k, v in SAMPLE_GROUP_COLUMNS.items():\n",
    "    samplesheet_valid[k] = np.nan\n",
    "    for kg, vg in SAMPLE_GROUPS[k].items():\n",
    "        samplesheet_valid.loc[samplesheet_valid[v].map(lambda x: filter_group(x, kg)), k] = vg\n",
    "    assert not samplesheet_valid[k].isnull().any()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save metadata to csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push metadata to csv. \n",
    "\n",
    "metadata = samplesheet_valid[\n",
    "                        [SRX_COLUMN] + \n",
    "                        list(SAMPLE_CONDITIONS.keys()) + \n",
    "                        list(SAMPLE_GROUPS.keys()) + \n",
    "                        [c for c in KEEP_COLUMNS if c != SRX_COLUMN]\n",
    "                    ].copy()\n",
    "\n",
    "metadata.rename({SRX_COLUMN: 'accession'}, inplace=True, axis=1)\n",
    "\n",
    "\n",
    "# Collapse technical replicates into eachother by summing read counts across runs.\n",
    "if 'read_count' in metadata.columns:\n",
    "    metadata['read_count'] = metadata.groupby('accession')['read_count'].transform('sum')\n",
    "\n",
    "# Sample dataframe from output of nf-core rnaseq lists distinct samples by SRR*, \n",
    "# but groups samples by SRX* for analysis.\n",
    "metadata.drop_duplicates(inplace=True)\n",
    "\n",
    "single_groups = []\n",
    "for c in metadata.columns:\n",
    "    if not c.startswith('group') or c.startswith('condition'):\n",
    "        continue\n",
    "    if len(metadata[c].value_counts()) == 1:\n",
    "        single_groups.append(c)\n",
    "\n",
    "metadata.drop(single_groups, axis=1, inplace=True)\n",
    "\n",
    "metadata.to_csv(METADATA_FH,index=False)\n",
    "metadata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
