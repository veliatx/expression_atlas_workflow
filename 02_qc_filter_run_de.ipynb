{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QC Data and Filter Samples for DE testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "from IPython.display import HTML\n",
    "import html\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pydeseq2.ds import DeseqStats\n",
    "from pydeseq2.dds import DeseqDataSet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CPUS = 8\n",
    "# DATA_PATH = os.getcwd()\n",
    "# DATA_PATH = '/data/expression_atlas/v1/GSE139358/'\n",
    "# DATA_PATH = '/data/expression_atlas/v1/GSE112087/'\n",
    "# DATA_PATH = '/data/expression_atlas/v1/GSE122459/'\n",
    "# DATA_PATH = '/data/expression_atlas/v1/GSE102371'\n",
    "# DATA_PATH = '/data/expression_atlas/v1/GSE110914/'\n",
    "# DATA_PATH = '/data/expression_atlas/v1/GSE162828/'\n",
    "# DATA_PATH = '/data/expression_atlas/v1/GSE102371/'\n",
    "DATA_PATH = '/data/expression_atlas/v1/GSE80183/'\n",
    "\n",
    "\n",
    "MULTIQC_PATH = os.path.join(DATA_PATH, 'rnaseq_output/multiqc/star_salmon/multiqc_report.html')\n",
    "\n",
    "COUNT_PATH = os.path.join(DATA_PATH, 'rnaseq_output/star_salmon')\n",
    "METADATA_FH = '' + '%s_metadata.csv' % DATA_PATH.rstrip('/').split('/')[-1]\n",
    "\n",
    "RESULTS_PATH = '' + 'results/%s' % DATA_PATH.rstrip('/').split('/')[-1]\n",
    "\n",
    "if not os.path.exists('results'):\n",
    "    os.mkdir('results')\n",
    "DDS_TRANSCRIPT_FH = '' + 'results/%s_dds_transcript.h5_ad' % DATA_PATH.rstrip('/').split('/')[-1]\n",
    "DDS_GENE_FH = '' + 'results/%s_dds_gene.h5_ad' % DATA_PATH.rstrip('/').split('/')[-1]\n",
    "\n",
    "TRANSCRIPT_SUM_FILTER = 10\n",
    "TRANSCRIPT_PSEUDOCOUNT = 0\n",
    "GENE_SUM_FILTER = 10\n",
    "GENE_PSEUDOCOUNT = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the MulitQC report into notebook. Note srcdoc was reqiured to get the html rendered without screwing up the \n",
    "# styling of the notebook while using an iframe. Buttons on the side don't work, but everything else seems to work fine.\n",
    "\n",
    "with open(MULTIQC_PATH,'r') as f_in:\n",
    "    html_raw = html.escape(f_in.read())\n",
    "\n",
    "HTML('<iframe srcdoc=\"%s\" width=\"1200px\" height=\"1000px\"></iframe>' % html_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read sample metadata into dataframe\n",
    "\n",
    "metadata = pd.read_csv(os.path.join('', METADATA_FH), index_col=0)\n",
    "smallest_condition_size = metadata[[c for c in metadata.columns if c.startswith('condition')]].value_counts()[-1]\n",
    "\n",
    "metadata, smallest_condition_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge effective lengths and average across all runs for transcript and gene dataframes.\n",
    "\n",
    "# Build the transcript length dataframe off of the first sample in the metadata dataframe.\n",
    "transcript_length = pd.read_csv(os.path.join(COUNT_PATH, metadata.index[0], 'quant.sf'), delimiter= '\\t', index_col=0)\n",
    "transcript_length.rename({'EffectiveLength':'EffectiveLength_%s' % metadata.index[0]}, axis=1, inplace=True)\n",
    "transcript_length.drop(['Length', 'TPM', 'NumReads'], inplace=True, axis=1)\n",
    "\n",
    "gene_length = pd.read_csv(os.path.join(COUNT_PATH, metadata.index[0], 'quant.genes.sf'), delimiter= '\\t', index_col=0)\n",
    "gene_length.rename({'EffectiveLength':'EffectiveLength_%s' % metadata.index[0]}, axis=1, inplace=True)\n",
    "gene_length.drop(['Length', 'TPM', 'NumReads'], inplace=True, axis=1)\n",
    "\n",
    "# Populate samples into effective length dataframe with remaining samples.\n",
    "for srx in tqdm(metadata.index[1:]):\n",
    "    df = pd.read_csv(os.path.join(COUNT_PATH, srx, 'quant.sf'), delimiter='\\t', index_col=0)\n",
    "    df.drop(['Length', 'TPM', 'NumReads'], inplace=True, axis=1)\n",
    "    df.rename({'EffectiveLength':'EffectiveLength_%s' % srx}, axis=1, inplace=True)\n",
    "    transcript_length = transcript_length.merge(df, on='Name')\n",
    "\n",
    "    df_gene = pd.read_csv(os.path.join(COUNT_PATH, srx, 'quant.genes.sf'), delimiter='\\t', index_col=0)\n",
    "    df_gene.drop(['Length', 'TPM', 'NumReads'], inplace=True, axis=1)\n",
    "    df_gene.rename({'EffectiveLength':'EffectiveLength_%s' % srx}, axis=1, inplace=True)\n",
    "    gene_length = gene_length.merge(df_gene, on='Name')\n",
    "\n",
    "\n",
    "# Average effective lengths. It would probably be better to use a weighted averaging similar to tximport.\n",
    "transcript_length['length'] = transcript_length.mean(axis=1)\n",
    "gene_length['length'] = gene_length.mean(axis=1)\n",
    "transcript_length.drop([c for c in transcript_length.columns if c.startswith('EffectiveLength_')], inplace=True, axis=1)\n",
    "gene_length.drop([c for c in gene_length.columns if c.startswith('EffectiveLength_')], inplace=True, axis=1)\n",
    "\n",
    "transcript_length.shape, gene_length.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in transcript and gene count/TPM dataframes.\n",
    "\n",
    "expression = pd.read_csv(os.path.join(COUNT_PATH, 'salmon.merged.transcript_counts.tsv'), delimiter = '\\t', index_col=0)\n",
    "gene_transcript_mapping = expression[['gene_id']].copy().reset_index()\n",
    "expression.drop('gene_id', inplace=True, axis=1)\n",
    "\n",
    "tpm = pd.read_csv(os.path.join(COUNT_PATH, 'salmon.merged.transcript_tpm.tsv'), delimiter = '\\t', index_col=0)\n",
    "tpm.drop('gene_id', inplace=True, axis=1)\n",
    "\n",
    "# See: https://nf-co.re/rnaseq/3.12.0/docs/output#salmon on output choice below \n",
    "# salmon.merged.gene_counts_length_scaled.tsv is the gene-level output of nf-core rnaseq that is bias-corrected\n",
    "# and is already scaled by potential transcript length\n",
    "expression_gene = pd.read_csv(os.path.join(COUNT_PATH, 'salmon.merged.gene_counts_length_scaled.tsv'), delimiter='\\t', index_col=0)\n",
    "expression_gene.drop('gene_name', inplace=True, axis=1)\n",
    "\n",
    "tpm_gene = pd.read_csv(os.path.join(COUNT_PATH, 'salmon.merged.gene_tpm.tsv'), delimiter='\\t', index_col=0)\n",
    "tpm_gene.drop('gene_name', inplace=True, axis=1)\n",
    "\n",
    "expression.shape, expression_gene.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter expression dataframes on samples not in metadata.csv\n",
    "\n",
    "samples_to_drop = [c for c in expression.columns if c not in metadata.index]\n",
    "\n",
    "expression.drop(samples_to_drop, axis=1, inplace=True)\n",
    "expression_gene.drop(samples_to_drop, axis=1, inplace=True)\n",
    "tpm.drop(samples_to_drop, axis=1, inplace=True)\n",
    "tpm_gene.drop(samples_to_drop, axis=1, inplace=True)\n",
    "expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop specific samples from dataframe. Provide accession name of samples to remove from analysis.\n",
    "\n",
    "samples_to_drop = []\n",
    "# samples_to_drop = ['SRX3729696']\n",
    "# samples_to_drop = ['SRX9647190']\n",
    "expression.drop(samples_to_drop, axis=1, inplace=True)\n",
    "expression_gene.drop(samples_to_drop, axis=1, inplace=True)\n",
    "tpm.drop(samples_to_drop, axis=1, inplace=True)\n",
    "tpm_gene.drop(samples_to_drop, axis=1, inplace=True)\n",
    "metadata.drop(samples_to_drop, axis=1, inplace=True)\n",
    "expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop specific conditions/groups from metadata dataframe. \n",
    "\n",
    "groups_to_drop = []\n",
    "metadata.drop(groups_to_drop, axis=1, inplace=True)\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter expression dataframe and prepare for QC/EDA.\n",
    "\n",
    "filtered_expression_transcript = expression.T.copy()\n",
    "filtered_expression_transcript = filtered_expression_transcript[\n",
    "                                    filtered_expression_transcript.columns[\n",
    "                                        filtered_expression_transcript.sum(axis=0) >= TRANSCRIPT_SUM_FILTER\n",
    "                                        ]\n",
    "                                    ]\n",
    "\n",
    "# Tag to take another look, filter later \n",
    "filtered_expression_transcript = filtered_expression_transcript[\n",
    "                                    filtered_expression_transcript.columns[\n",
    "                                        (filtered_expression_transcript >= TRANSCRIPT_SUM_FILTER).sum(axis=0) >\n",
    "                                            smallest_condition_size\n",
    "                                        ]\n",
    "                                    ]\n",
    "\n",
    "filtered_tpm_transcript = tpm.T.copy()\n",
    "filtered_tpm_transcript = filtered_tpm_transcript[filtered_expression_transcript.columns]\n",
    "\n",
    "filtered_expression_gene = expression_gene.T.copy()\n",
    "filtered_expression_gene = filtered_expression_gene[\n",
    "                                    filtered_expression_gene.columns[\n",
    "                                        filtered_expression_gene.sum(axis=0) >= GENE_SUM_FILTER\n",
    "                                        ]\n",
    "                                    ]\n",
    "\n",
    "# Tag to take another look, filter later \n",
    "filtered_expression_gene = filtered_expression_gene[\n",
    "                                    filtered_expression_gene.columns[\n",
    "                                        (filtered_expression_gene >= GENE_SUM_FILTER).sum(axis=0) > \n",
    "                                            smallest_condition_size\n",
    "                                        ]\n",
    "                                    ]\n",
    "\n",
    "filtered_tpm_gene = tpm_gene.T.copy()\n",
    "filtered_tpm_gene = filtered_tpm_gene[filtered_expression_gene.columns]\n",
    "\n",
    "assert (\n",
    "        all([i == j for i,j in zip(filtered_expression_gene.columns, filtered_tpm_gene.columns)]) and \n",
    "        all([i == j for i,j in zip(filtered_expression_transcript.columns, filtered_tpm_transcript.columns)]) and \n",
    "        all([i == j for i,j in zip(filtered_expression_gene.index, filtered_tpm_gene.index)]) and\n",
    "        all([i == j for i,j in zip(filtered_expression_transcript.index, filtered_tpm_transcript.index)])\n",
    "    )\n",
    "\n",
    "(   expression.shape, \n",
    "    filtered_expression_transcript.shape, \n",
    "    expression_gene.shape, \n",
    "    filtered_expression_gene.shape, \n",
    "    filtered_tpm_transcript.shape, \n",
    "    filtered_tpm_gene.shape, \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Deseq dataframe (AnnData object).\n",
    "\n",
    "# DeseqDataSet expects integers in counts matrix, need to check in on the default method for \n",
    "# rounding fractional counts to integers in tximport.\n",
    " \n",
    "dds = DeseqDataSet(\n",
    "    counts = filtered_expression_transcript.astype(int), \n",
    "    metadata = metadata, \n",
    "    design_factors = \n",
    "        [c for c in metadata.columns if c.startswith('group')]+\n",
    "        [c for c in metadata.columns if c.startswith('condition')],\n",
    "    refit_cooks = True, \n",
    "    n_cpus = NUM_CPUS, \n",
    "    )\n",
    "\n",
    "dds_gene = DeseqDataSet(\n",
    "    counts = filtered_expression_gene.astype(int), \n",
    "    metadata = metadata, \n",
    "    design_factors = \n",
    "        [c for c in metadata.columns if c.startswith('group')]+\n",
    "        [c for c in metadata.columns if c.startswith('condition')],\n",
    "    refit_cooks = True, \n",
    "    n_cpus = NUM_CPUS, \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set gene-transcript mapping attribute in uns for comparisons between \n",
    "# gene- and transcript-level quantifications.\n",
    "\n",
    "dds.uns['gene_transcript_mapping'] = gene_transcript_mapping\n",
    "dds_gene.uns['gene_transcript_mapping'] = gene_transcript_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set raw TPMs as layer in dds objects.\n",
    "\n",
    "dds.layers['raw_tpm'] = np.array(filtered_tpm_transcript)\n",
    "dds_gene.layers['raw_tpm'] = np.array(filtered_tpm_gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the average effective lengths into the var dataframe.\n",
    "\n",
    "dds.var = dds.var.merge(transcript_length, left_index=True, right_index=True)\n",
    "dds_gene.var = dds_gene.var.merge(gene_length, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute size-factors and library sizes.\n",
    "\n",
    "dds.fit_size_factors()\n",
    "dds.obs['size_factors'] = dds.obsm['size_factors']\n",
    "dds.obs['lib_sizes'] = dds.X.sum(axis=1)\n",
    "\n",
    "dds_gene.fit_size_factors()\n",
    "dds_gene.obs['size_factors'] = dds_gene.obsm['size_factors']\n",
    "dds_gene.obs['lib_sizes'] = dds_gene.X.sum(axis=1)\n",
    "\n",
    "dds.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance-stabilizing transformation.\n",
    "\n",
    "dds.vst()\n",
    "dds_gene.vst()\n",
    "\n",
    "dds.layers['vst_counts'], dds_gene.layers['vst_counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set recoverable count data.\n",
    "\n",
    "dds.layers['counts'] = dds.X.copy()\n",
    "dds_gene.layers['counts'] = dds_gene.X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute fractional counts to get a quick idea for any weird skews in library composition.\n",
    "\n",
    "dds.layers['fraction_counts'] = dds.layers['counts'] / np.reshape(dds.layers['counts'].sum(axis=1), (-1,1))\n",
    "dds_gene.layers['fraction_counts'] = dds_gene.layers['counts'] / np.reshape(dds_gene.layers['counts'].sum(axis=1), (-1,1))\n",
    "\n",
    "dds.layers['fraction_counts'], dds_gene.layers['fraction_counts']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CDF of fractional composition of libraries. \n",
    "\n",
    "ax_transcript = sns.ecdfplot(np.log2(dds.layers['fraction_counts'].T))\n",
    "ax_transcript.set_xlabel('log2 fraction counts')\n",
    "ax_transcript.legend(\n",
    "        labels=dds.obs.index, \n",
    "        loc='upper left', \n",
    "        bbox_to_anchor=(1.,1.), \n",
    "        ncols=1 if len(dds.obs.index) < 10 else int(len(dds.obs.index)/10),\n",
    "        frameon=False,\n",
    "    )\n",
    "ax_transcript.set_title('transcript')\n",
    "plt.show()\n",
    "\n",
    "ax_gene = sns.ecdfplot(np.log2(dds_gene.layers['fraction_counts'].T))\n",
    "ax_gene.set_xlabel('log2 fraction counts')\n",
    "ax_gene.legend(\n",
    "        labels=dds_gene.obs.index, \n",
    "        loc='upper left', \n",
    "        bbox_to_anchor=(1.,1.), \n",
    "        ncols=1 if len(dds_gene.obs.index) < 10 else int(len(dds_gene.obs.index)/10),\n",
    "        frameon=False,\n",
    "    )\n",
    "ax_gene.set_title('gene')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace count matrix with variance-transformed counts, following DESeq2 recommendation\n",
    "# for preprocessing count data before QC visualization.\n",
    "\n",
    "dds.X = dds.layers['vst_counts'].copy()\n",
    "dds_gene.X = dds_gene.layers['vst_counts'].copy()\n",
    "\n",
    "np.nan_to_num(dds.X, copy=False)\n",
    "np.nan_to_num(dds_gene.X, copy=False)\n",
    "\n",
    "dds.layers['counts'], dds.X, dds.layers['vst_counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale transformed variables.\n",
    "\n",
    "sc.pp.scale(dds)\n",
    "sc.pp.scale(dds_gene)\n",
    "\n",
    "np.nan_to_num(dds.X, copy=False)\n",
    "np.nan_to_num(dds_gene.X, copy=False)\n",
    "\n",
    "dds.X.mean(axis=0), dds.X.std(axis=0), dds_gene.X.mean(axis=0), dds_gene.X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminary PCA on transcript- and gene-level data.\n",
    "\n",
    "suffix_size = 4\n",
    "\n",
    "sc.pp.pca(dds)\n",
    "ax_transcript_pca = sc.pl.pca( \n",
    "    dds, \n",
    "    color=\n",
    "        [c for c in dds.obs.columns if c.startswith('group')]+\n",
    "        [c for c in dds.obs.columns if c.startswith('condition')]+\n",
    "        ['lib_sizes'], \n",
    "    size = 128,\n",
    "    show=False,\n",
    "    )\n",
    "\n",
    "for i, s in enumerate(dds.obsm['X_pca']):\n",
    "    if type(ax_transcript_pca) == list:\n",
    "        for ax in ax_transcript_pca:\n",
    "            ax.text(s[0], s[1], dds.obs.index[i][-suffix_size:])\n",
    "    else:\n",
    "        ax_transcript_pca.text(s[0], s[1], dds.obs.index[i][-suffix_size:])\n",
    "\n",
    "sc.pp.pca(dds_gene)\n",
    "ax_gene_pca = sc.pl.pca(\n",
    "    dds_gene, \n",
    "    color=\n",
    "        [c for c in dds_gene.obs.columns if c.startswith('group')]+\n",
    "        [c for c in dds_gene.obs.columns if c.startswith('condition')]+\n",
    "        ['lib_sizes'],\n",
    "    size = 128,\n",
    "    show=False, \n",
    "    )\n",
    "\n",
    "for i, s in enumerate(dds_gene.obsm['X_pca']):\n",
    "    if type(ax_gene_pca) == list:\n",
    "        for ax in ax_gene_pca:\n",
    "            ax.text(s[0], s[1], dds_gene.obs.index[i][-suffix_size:])\n",
    "    else:\n",
    "        ax_gene_pca.text(s[0], s[1], dds_gene.obs.index[i][-suffix_size:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot explained variance ratios.\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "ax[0].plot(dds.uns['pca']['variance_ratio'])\n",
    "ax[1].plot(dds_gene.uns['pca']['variance_ratio'])\n",
    "\n",
    "ax[0].set_ylabel('fraction explained variance')\n",
    "ax[0].set_xlabel('PC')\n",
    "ax[1].set_xlabel('PC')\n",
    "ax[0].set_title('Transcript')\n",
    "ax[1].set_title('Gene')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loadings for first 3 PCs.\n",
    "\n",
    "sc.pl.pca_loadings(dds, components = '1,2,3')\n",
    "sc.pl.pca_loadings(dds_gene, components = '1,2,3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample-sample pearson correlation.\n",
    "\n",
    "dds.layers['vst_counts'].shape\n",
    "dds_gene.layers['vst_counts'].shape\n",
    "\n",
    "dist = np.corrcoef(np.nan_to_num(dds.layers['vst_counts'] / \n",
    "                                 np.reshape(dds.obs['lib_sizes'], (-1, 1)), copy=False))\n",
    "ax_transcript = sns.heatmap(\n",
    "                dist, \n",
    "                xticklabels=dds.obs.index, \n",
    "                yticklabels=dds.obs['condition-1'], \n",
    "                cbar_kws={'label': 'pearson r'}, \n",
    "            )\n",
    "ax_transcript.set_title('transcript')\n",
    "plt.show()\n",
    "\n",
    "dist = np.corrcoef(np.nan_to_num(dds_gene.layers['vst_counts'] / \n",
    "                                 np.reshape(dds_gene.obs['lib_sizes'], (-1, 1)), copy=False))\n",
    "ax_gene = sns.heatmap(\n",
    "                dist, \n",
    "                xticklabels=dds_gene.obs.index, \n",
    "                yticklabels=dds_gene.obs['condition-1'], \n",
    "                cbar_kws={'label': 'pearson r'},\n",
    "            )\n",
    "ax_gene.set_title('gene')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore the original counts data.\n",
    "\n",
    "dds.X = dds.layers['counts'].copy()\n",
    "dds_gene.X = dds_gene.layers['counts'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit dispersions, logFCs, and calculate cooks.\n",
    "\n",
    "dds.deseq2()\n",
    "dds_gene.deseq2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot fitted dispersions.\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "ax[0].scatter(\n",
    "        np.log(dds.varm['_normed_means']), \n",
    "        np.log(dds.varm['genewise_dispersions']), \n",
    "        s=1, \n",
    "        alpha=0.01, \n",
    "        label='raw',\n",
    "    )\n",
    "ax[0].scatter(\n",
    "        np.log(dds.varm['_normed_means']), \n",
    "        np.log(dds.varm['dispersions']), \n",
    "        s=1, \n",
    "        alpha=0.01, \n",
    "        label='squeezed',\n",
    "    )\n",
    "ax[0].scatter(\n",
    "        np.log(dds.varm['_normed_means']), \n",
    "        np.log(dds.varm['fitted_dispersions']), \n",
    "        s=1, \n",
    "        alpha=0.01, \n",
    "        label='trended', \n",
    "        c='r', \n",
    "    )\n",
    "ax[0].set_ylabel('log dispersions')\n",
    "ax[0].set_xlabel('log normalized mean')\n",
    "ax[0].set_title('transcript-level')\n",
    "ax[0].legend(frameon=False)\n",
    "legend = ax[0].legend(frameon=False)\n",
    "for lh in legend.legend_handles:\n",
    "    lh.set_alpha(1)\n",
    "\n",
    "ax[1].scatter(\n",
    "        np.log(dds_gene.varm['_normed_means']), \n",
    "        np.log(dds_gene.varm['genewise_dispersions']), \n",
    "        s=1, \n",
    "        alpha=0.01, \n",
    "        label='raw',\n",
    "    )\n",
    "ax[1].scatter(\n",
    "        np.log(dds_gene.varm['_normed_means']), \n",
    "        np.log(dds_gene.varm['dispersions']), \n",
    "        s=1, \n",
    "        alpha=0.01, \n",
    "        label='squeezed',\n",
    "    )\n",
    "ax[1].scatter(\n",
    "        np.log(dds_gene.varm['_normed_means']), \n",
    "        np.log(dds_gene.varm['fitted_dispersions']), \n",
    "        s=1, \n",
    "        alpha=0.01, \n",
    "        label='trended', \n",
    "        c='r', \n",
    "    )\n",
    "ax[1].set_xlabel('log normalized mean')\n",
    "ax[1].set_title('gene-level')\n",
    "legend = ax[1].legend(frameon=False)\n",
    "for lh in legend.legend_handles:\n",
    "    lh.set_alpha(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually define contrasts given conditions in metadata dataframe.\n",
    "\n",
    "for c in [c for c in dds.obs.columns if c.startswith('condition')]:\n",
    "    print(dds.obs[c].unique())\n",
    "\n",
    "# Pydeseq2 contrasts require condition-name, treatment level, reference level format.\n",
    "# contrasts = {\n",
    "#     'SLE_v_control': ['condition-1','TREAT-1','CONTROL'],\n",
    "#     }\n",
    "\n",
    "contrasts = {\n",
    "    'SLE_v_control': ['condition-1','DISEASE','CONTROL'],\n",
    "    }\n",
    "\n",
    "# contrasts = {\n",
    "#     'T1D_v_control': ['condition-1','TREAT-1','CONTROL'],\n",
    "#     'preT1D_v_control': ['condition-1','TREAT-2','CONTROL']\n",
    "#     }\n",
    "\n",
    "# contrasts = {\n",
    "#     'SLE_v_control': ['condition-1','TREAT-1','CONTROL']\n",
    "#     }\n",
    "\n",
    "# contrasts = {\n",
    "#     'T1D_v_control': ['condition-1','TREAT-1','CONTROL'],\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dds.obsm['design_matrix'], dds_gene.obsm['design_matrix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Stats object. Define relevant contrasts for DE and LogFC computations and run tests. \n",
    "\n",
    "# Holds all DeseqStats objects as defined in contrasts.\n",
    "dds.uns['stat_results'] = {}\n",
    "dds_gene.uns['stat_results'] = {}\n",
    "\n",
    "for k, v in contrasts.items():\n",
    "\n",
    "    stat_res = DeseqStats(dds, contrast=v, n_cpus=NUM_CPUS)\n",
    "    stat_res_gene = DeseqStats(dds_gene, contrast=v, n_cpus=NUM_CPUS)\n",
    "\n",
    "    stat_res.summary()\n",
    "    stat_res_gene.summary()\n",
    "\n",
    "    stat_res.lfc_shrink()\n",
    "    stat_res_gene.lfc_shrink()\n",
    "    \n",
    "    dds.uns['stat_results'][k] = stat_res.results_df\n",
    "    dds_gene.uns['stat_results'][k] = stat_res_gene.results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate -log10_padj and fill NaN. NaN caused by filtering genes with cooks outliers.\n",
    "\n",
    "for i, k in enumerate(contrasts.keys()):\n",
    "    \n",
    "    dds.uns['stat_results'][k]['-log10_padj'] = -1. * np.log10(dds.uns['stat_results'][k]['padj'])\n",
    "    dds_gene.uns['stat_results'][k]['-log10_padj'] = -1. * np.log10(dds_gene.uns['stat_results'][k]['padj'])\n",
    "\n",
    "    dds.uns['stat_results'][k]['-log10_padj'].fillna(0.0, inplace=True)\n",
    "    dds_gene.uns['stat_results'][k]['-log10_padj'].fillna(0.0, inplace=True)\n",
    "\n",
    "    dds.uns['stat_results'][k]['-log10_padj'].replace(np.inf, 30., inplace=True)\n",
    "    dds_gene.uns['stat_results'][k]['-log10_padj'].replace(np.inf, 30., inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump results dataframes to results folder.\n",
    "\n",
    "for k in contrasts.keys():\n",
    "\n",
    "    dds.uns['stat_results'][k].to_csv('%s_%s_%s.csv' % (RESULTS_PATH, 'transcript', k))\n",
    "    dds_gene.uns['stat_results'][k].to_csv('%s_%s_%s.csv' % (RESULTS_PATH, 'gene', k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write dds objects to files for DE and LogFC calculations.\n",
    "\n",
    "# Pydeseq2 supports trend_coeffs/replaced as either np.array or pd.series, np.array required for \n",
    "# saving h5-formatted AnnData objects.\n",
    "dds.uns['trend_coeffs'] = np.array(dds.uns['trend_coeffs'])\n",
    "dds_gene.uns['trend_coeffs'] = np.array(dds_gene.uns['trend_coeffs'])\n",
    "\n",
    "dds.varm['replaced'] = np.array(dds.varm['replaced'])\n",
    "dds_gene.varm['replaced'] = np.array(dds_gene.varm['replaced'])\n",
    "\n",
    "# Add contrasts to uns.\n",
    "dds.uns['contrasts'] = contrasts\n",
    "dds_gene.uns['contrasts'] = contrasts\n",
    "\n",
    "# DeseqDataSet doesn't have native support for writing h5, save as AnnData objects and restore from\n",
    "# AnnData objects.\n",
    "\n",
    "dds.write(DDS_TRANSCRIPT_FH)\n",
    "dds_gene.write(DDS_GENE_FH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
